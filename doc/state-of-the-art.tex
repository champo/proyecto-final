\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[spanish]{babel}
\usepackage[pdftex,usenames,dvipsnames]{color}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage[small,bf]{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{titlesec}
\usepackage{csquotes}
\usepackage[backend=bibtex]{biblatex}
\usepackage{titling}
% \usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithm}


%%%%% BEGIN ALGPSEUDOCODE STUFF %%%%%%
\algdef{SxnE}[FOREACH]{ForEach}{EndFor}[1]{\algorithmicfor\ #1\ \algorithmicdo}
% LEAVES BLANK LINE AT END \algblockdefx[FOREACH]{ForEach}{EndFor}{\textbf{for each }}{}
\algdef{SxnE}[FOR]{For}{EndFor}[1]{\algorithmicfor\ #1\ \algorithmicdo}
\algdef{SxnE}[WHILE]{While}{EndWhile}[1]{\algorithmicwhile\ #1\ \algorithmicdo}
\algdef{SxnE}[IF]{If}{EndIf}[1]{\algorithmicif\ #1\ \algorithmicthen}
\algdef{cxnE}{IF}{Else}{EndIf}


\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\algnewcommand\algorithmicauxiliary{\textbf{Auxiliary:}}
\algnewcommand\Auxiliary{\item[\algorithmicauxiliary]}

\floatname{algorithm}{Algoritmo}
%%%%% END ALGPSEUDOCODE STUFF %%%%%%


\DeclareMathOperator*{\argmin}{arg\,min}
\addbibresource{references}
\DeclareFieldFormat[inbook]{citetitle}{#1}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\titleformat{\section}{\small\center\bfseries}{\thesection.}{0.5em}{\normalsize\uppercase}
\titleformat{\subsection}{\small\center\bfseries}{}{0.5em}{\small\uppercase}

\def\customabstract{\vspace{.5em}
    {\small\center{\textbf{RESUMEN}} \\[0.5em] \relax%
    }}
\def\endkeywords{\par}

\def\keywords{\vspace{.5em}
    {\textit{Palabras clave: }
    }}
\def\endkeywords{\par}

% TITLE Configuration
\setlength{\droptitle}{-30pt}
\pretitle{\begin{center}\Huge\begin{rmfamily}}
\posttitle{\par\end{rmfamily}\end{center}\vskip 0.5em}
\preauthor{\begin{center}
        \large \lineskip 0.5em%
\begin{tabular}[t]{c}}
\postauthor{\end{tabular}\normalsize
    \\[1em] Estudiantes del Instituto Tecnológico de Buenos Aires
\par\end{center}}
\predate{\begin{center}\small}
\postdate{\par\end{center}}

% Headers
\addtolength{\voffset}{-40pt}
\addtolength{\textheight}{80pt}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\lhead{\small No publicado}
\rhead{\small \thepage}
\cfoot{\small Copyright \copyright 2013 ITBA}

% Metadata
\title{}
\date{20 de Septiembre de 2013}
\author{Civile, Juan Pablo \and Crespo, Álvaro \and Ordano, Esteban }

\begin{document}

\pagestyle{fancy}
\maketitle
\thispagestyle{fancy}

\begin{customabstract}
\textbf{
Las técnicas de seguimiento de objetos en videos tienen numerosas aplicaciones
en las actividades cotidianas. En el ámbito deportivo pueden ser útiles para
soportar (o hasta reemplazar) las decisiones de los jueces o árbitros del
juego, permitir a los deportistas mejorar su juego mediante el análisis de sus
movimientos, otorgar estadísticas y métricas a los fanáticos del deporte, entre
otras aplicaciones. Se describe a lo largo de este trabajo técnicas aplicables
al problema de seguimiento de múltiples jugadores de fútbol mediante el uso de
una o varias cámaras de video. Se presentan las bases matemáticas para estos
métodos y se analizarán características de cada una junto con las limitaciones
y la factibilidad de conocer el estado del juego completo para cada momento.
} \end{customabstract}

\part*{Introducción}

Dentro del área de análisis de imágenes, uno de los problemas más relevantes y
estudiados es el problema de reconocer un objeto a partir de una secuencia de
imágenes para seguir su posición, detectar cambios de orientación o en su
forma, reconocerlo aunque esté parcialmente (o totalmente) ocluído, y otras
variaciones del problema. Tiene aplicaciones en muchos campos, como ser
medicina, control automatizado de procesos industriales, reconocimiento facial
y gestual, etcétera.

Existe una tendencia en los deportes en las últimas décadas por pasar a ser
controlados automáticamente. Un ejemplo de esto son las cámaras de alta
velocidad en tenis, y las repeticiones y análisis de los árbitros en fútbol
americano. Para la industria del entretenimiento, la tendencia a utilizar
mecanismos automatizados de análisis del estado del juego provee datos
estadísticos, como en el caso de fútbol puede ser poseción de pelota, cantidad
de pases exitosos, tiros al arco, fracción del tiempo que cada jugador trotó,
corrió o caminó, entre otros.

Para permitir estos análisis de manera automática y recuperar datos con alto
nivel semántico, se debe plantear un sistema que automatice la recolección
y procesamiento de imágenes. En este trabajo se estudia el estado
actual de las distintas tecnologías usadas para este fin.

En la sección \ref{sec:tracking} se describen los algoritmos de seguimiento
de objetos categorizados en cuatro familias:
\textit{Predictores Lineales},
\textit{Aprendizaje Lineal},
\textit{Corte de Grafos},
y \textit{Contornos Activos}.

En la sección \ref{sec:var-camaras} se discuten los avances modernos en esta
rama y los sistemas implementados que resuelven el problema de seguimiento de
jugadores, pelota, y estado del juego. Se describen también las técnicas con
mayor nivel semántico que detectan movimientos de jugadores, pases de pelota,
tiros al arco, entre otros. Se dividen los mismos categorizados por los
sistemas de cámaras utilizadas (una sola cámara fija, video televizado, o
múltiples cámaras fijas).

\newpage

\section{Algoritmos de seguimiento}
\label{sec:tracking}

A continuación se describen los algoritmos de cuatro familias dentro de la rama
de análisis de imágenes para seguimiento de objetos.

\subsection{Predictores Lineales}

Un \textit{Predictor Lineal} es una funcion que toma los valores de una serie
de variables aleatorias y predice el valor de una variable dependiente.  La
funcion tiene la forma $f(x_1, ..., x_n) = \beta_0 + \beta_1 x_1 + \dots +
\beta_n x_n$, donde $x_i$ es una variable aleatoria y $\beta_i$ una constante.
Se dice que el predictor es lineal al obligarse a $\beta_i$ a existir en los
numeros reales.

En \cite{alp, original-linear-predictors} los autores utilizan predictores para
hacer seguimiento de objetos en video.  El objetivo es relacionar el cambio de
valor de varios píxeles cuadro a cuadro con el movimiento del objeto entre
dichos cuadros.  Para soportar cualquier clase de movimiento, este se
representa mediante una homografia (\cite{homography-estimation}), $H \in
R^{3,3}$.

Entonces los predictores se representan mediante una matriz $A \in
\mathbb{R}^{9xn}$ donde cada fila representa una funcion de prediccion.  De 2
cuadros consecutivos se obtiene el vector de cambios de valor de píxeles $X =
(x_1, \dots, x_n)$ y se computa:

\begin{eqnarray*}
    AX = B \\
    B = (h_{1,1}, h_{1,2}, h_{1,3}, h_{2,1}, h_{2,2}, h_{2,3}, h_{3,1}, h_{3,2}, h_{3,3})
\end{eqnarray*}

Donde $B$ contiene los valores de la homografia ($H$) de movimiento entre los cuadros.

\subsubsection{Calculo de los predictores}
% TODO: Aclarar que es perturbar
% TODO: Aclarar que el calculo de la homografia de la perturbacion es directa
Para obtener la relacion $A$ se utiliza un paso inicial de entrenamiento.
Primero se determina la posicion del objeto en un cuadro de manera supervisada.
Una vez conocida la posicion, se toman $n$ muestras de valores de píxeles en ese cuadro.

Luego se crean $m$ perturbaciones de la posicion del objeto, y se computa la homografia $H_i$ que representa esa perturbacion.
Llamemos al vector que representa esa homografia $B_i$.
Ademas, tomamos muestras de valores de píxeles ($X_i$) con sus posiciones alteradas por la homografia $H_i$.
Se puede entonces plantear:
\begin{equation}
    A \left( X_1 \lvert \dots \lvert X_m \right) = \left( B_1 \lvert \dots \lvert B_m \right)
\end{equation}
Que es un sistema de ecuaciones lineales que puede ser resulto de manera sencilla.

\subsubsection{Mejoras}

Para mejorar la efectividad de los algoritmos, se calculan varios predictores y se disponen en capas.
Cada capa se construye para buscar cambios de posicion cada vez mas pequeños.
Es decir, la primer capa busca cambios bruscos y la ultima pequeños cambios.

\citeauthor*{alp} (\cite{alp}) introducen manejo de oclusiones parciales de manera eficiente.
Para esto se divide el objeto en pequeñas secciones cuadradas, llamadas \textit{templates}, y se computa la matriz $A$ de la siguiente manera:
\begin{eqnarray*}
    Y &=& \left( B_1 \lvert \dots \lvert B_m \right) \\
    H &=& \left( X_1 \lvert \dots \lvert X_m \right) \\
    A &=& Y H^T(HH^T)^{-1}
\end{eqnarray*}
Esto permite mediante una formula compleja pero eficiente actualizar $A$ rapidamente para remover y agregar \textit{templates}.
O sea, permite ignorar secciones ocultas del objeto hasta que estas vuelven ser visibles.

\subsection{Aprendizaje Local}
% Local learning

El aprendizaje local es otra técnica que permite resolver el problema del seguimiento de objetos en secuencias de imágenes,
que ha sido también un tema de investigación en el área del aprendizaje automático \cite{local-learning-machine-learning} y usado principalmente en la clasificación
de imágenes, recuperación y reconocimiento de objetos.

A diferencia del aprendizaje global, que entrena un modelo global basado en
todos los datos de entrenamiento, local learning considera varios modelos locales, cada uno extraído de solamente un subconjunto de los datos de entrenamiento.
Este tipo de enfoque enfatiza la idea de que un modelo local puede caracterizar mejor las propiedades intrínsecas y discriminativas de su correspondiente
subconjunto de datos, que un modelo global para el conjunto completo de datos. De esto se desprende que utilizar múltiples modelos locales puede ofrecer
mejores resultados cuando los datos están distribuidos de manera complicada o poco clara.

Si bien se puede pensar al seguimiento de objetos como una tarea de clasificación binaria
que apunta a separar el objeto del resto de la imagen o fondo, en realidad, el principal
problema reside en relacionar las apariciones del objeto entre 2 cuadros
consecutivos. Es por esto que la métrica de distancia para determinar el grado de
relación entre los puntos característicos \footnote{Los puntos característicos son puntos que se diferencian del resto por poseer o mostrar
ciertas características específicas y representativas. En el caso del seguimiento de objetos, son los puntos que mejor representan las características
del objeto, y que tienen mayor resistencia a variar con los diferentes cambios de escala, rotación, iluminación, etc...}
del objeto adquiere muchísima importancia.

Una simple medida de distancia como la distancia Euclideana puede llevar a algoritmos
de seguimiento inestables a la hora de diferenciar el objeto del fondo de la imagen. Por
lo tanto, se requiere una mejor y más compleja medida de distancia. Esta
es la idea princial que proponen Li y Lu \cite{local-learning}.

La función de distancia que usan es una combinación lineal de distancias elementales,
como se presenta en \cite{malisiewicz-cvpr08}. Definen a la función de distancia entre dos
punto característicos, a los que llaman \textit{ejemplares}, $e$ y $z$ como:

\begin{equation}
    \label{eq:distance-exemplar}
    D_{e}(z) = w_{e} \cdot d_{ez}
\end{equation}

donde $w_{e}$ es el vector de pesos de $e$, y $d_{ez}$ es el vector de distancia
n-dimensional entre $e$ y $z$, cuya n-ésima componente es la distancia $L_{2}$
entre la característica n-ésima de $e$ y $z$. Cabe destacar la función del vector de pesos, $w_{e}$,
que asigna una importancia relativa a la distancia de cada componente de $d_{ez}$.

Cada ejemplar está también asociado con un vector binario $B_{e}$, cuyos elementos
no nulos implican que los ejemplares correspondientes son similares a $e$. La
longitud de $B_{e}$ es igual al número de ejemplares con el mismo rótulo de $e$
\footnote{Se dice que un conjunto de ejemplares tiene un mismo rótulo si pertenecen a un mismo objeto. En el caso de seguimiento de objetos
más sencillo, exitirían 2 objetos: el objeto a seguir, y el fondo}.
Asumiendo que el aprendizaje de cada una de las funciones de distancia es
independiente del resto, se puede aprender $w_{e}$ y $B_{e}$, en un problema
de aprendizaje formulado de la siguiente manera:

\begin{equation}
    \label{eq:learning-problem}
    f_{1}(w,B) = \sum_{i \in C} B_{i}L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}
\begin{equation}
    {w^{*}, B^{*} = \argmin_{w,b} f_{1} (w,b) }
\end{equation}
\begin{equation}
   w \geq 0, B_{i} \in {0,1}, \sum_{i} B_{i} = M
\end{equation}

Nótese que se descarta el subíndice $e$ para tener una mayor claridad.
El conjunto $C$ es el conjunto de todos los ejemplares con el mismo rótulo que $e$ y $M$
es el mínimo número de ejemplares similares a $e$ (predefinido). La función $L$ puede ser
cualquier función de costo o pérdida
\footnote{Una función de pérdida o función de costo es simplemente una función que mapea un evento o los valores de una o más variables
a un número real que representa algún ``costo'' asociado al evento.}
, estrictamente positiva.
El vector de pesos $w$
se requiere que sea positivo para asegurar que una mayor distancia elemental (entre
alguna de las características) no pueda nunca llevar a una menor distancia total,
lo que implicaría una mayor similaridad.

Previo al seguimiento se deben especificar manualmente algunos parámetros iniciales,
como ser: punto central, ancho, altura y rotación del objeto. En el proceso de
entrenamiento, se aplica un Análisis de la Componente Principal
\footnote{El Análisis de la Componente Principal, es una técnica utilizada para reducir la dimensionalidad de un conjunto de datos.
Sirve para hallar las causas de la variabilidad de los datos y ordenarlas por importancia.
Técnicamente, busca la proyección según la cual los datos queden mejor representados en términos de cuadrados mínimos. Involucra el cálculo de la descomposición en
autovalores de la matriz de covarianza, normalmente tras centrar los datos en la media de cada atributo.}
de forma incremental en los primeros $F$ cuadros. En su trabajo, Li y Lu usan
$F = 5$.\cite{local-learning}

Los mejores resultados se seleccionan como muestras de entrenamiento positivas, mientras que
los peores resultados, se toman como muestras negativas. Se obtienen las características
RGB y LBP, como se presentan en \cite{tracking-bag-of-features}, de todas las muestras,
tanto positivas como negativas. Para cada muestra de entrenamiento, se calculan las
distancias elementales RGB y LBP con respecto a todas las restantes muestras.

Para obtener el vector de pesos óptimo, $w^{*}$, se calcula iterativamente $B$,
en función de $w$, y $w$ en función de $B$, asegurando que el valor de $f_{1}$ nunca
crezca, para encontrar un mínimo local. Este proceso iterativo se puede modelar de la
siguiente forma:

\begin{equation}
   \label{eq:local-learning-B-k}
   B^{k} = \argmin_{B} \sum_{i \in C} B_{i}L(-w^{k} \cdot d_{i})
\end{equation}
\begin{equation}
    \label{eq:local-learning-w-k}
    w^{k+1} = \argmin_{w} \sum_{i:B_{i}^{k}=1} L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}

Dado un $w^{k}$, que inicialmente podría ser aleatorio, se minimiza la ecuación
\ref{eq:local-learning-B-k} fijando $B_{i} = 1$ para los $M$ valores más
pequeños de $L(-w \cdot d_{i})$ y $0$ para el resto. Dado $B^{k}$, se puede
obtener fácilmente $w^{k}$, resolviendo la ecuación \ref{eq:local-learning-w-k}.
El aprendizaje termina cuando $B^{k+1}=B^{k}$.\\

En el proceso de seguimiento, para cada cuadro nuevo, se generan los
candidatos a ejemplares. En el área del aprendizaje automático, siempre se seleccionan candidatos
para luego verificar si cumplen las condiciones requeridas. En este caso, se quiere ver si los candidatos son
cumples con las condiciones necesarias para ser puntos característicos.
 de manera aleatoria, utilizando un filtro de partículas
\footnote{El filtro de partículas es un método empleado para estimar el estado de un sistema que cambia a lo largo del tiempo. Más
concretamente es un método de Montecarlo(secuencial). Se compone de un conjunto de muestras (las partículas) y unos valores, o pesos,
asociados a cada una de esas muestras. Las partículas son estados posibles del proceso, que se pueden representar como puntos en el espacio
de estados de dicho proceso.}
alrededor del resultado del
seguimiento en el cuadro anterior. Luego, se extraen las características
RGB y LBP como muestras de testeo. Después de calcular las distancias
elementales entre las muestras de testeo y de entrenamiento, se
forma una matriz de distancia, $D: N_{test} \times N_{train}$ a través
de las funciones de distancia entrenadas. Es decir, el elemento $(i,j)$ de la matriz $D$, contiene la distancia
entre la muestra de testeo $i$, y la muestra de entrenamiento $j$.

Finalmente, se utiliza la matriz $D$ para localizar al objeto como sigue:

\begin{equation}
    T = \argmin_{t} c \sum_{i} D_{i}(t) + (1 - c) \sum_{j} D_{j}(t)
\end{equation}

\begin{equation}
    \forall i \in \{i : i \in S^{+}, D_{i}(t) \leq Thr_{D} \}
\end{equation}
\begin{equation}
    \forall j \in \{j : j \in S^{+}, D_{j}(t) > Thr_{D} \}
\end{equation}

Donde $t$ es un posible candidato y $T$ es el objeto. $S^{+}$ es el
conjunto de muestras de entrenamiento positivas. La idea consiste en
que las muestras cuyas distancias sean menor que el umbral $Thr_{D}$
contribuyan más a localizar el objeto, entonces la constante $c$
debería tener un valor acorde, $c > 0.5$. Los autores Li y Lu utilizaron $c = 0.7$.\cite{local-learning}\\

El algoritmo de seguimiento se complementa con una adición más, que
intenta atacar el problema de los cambios de poses y las oclusiones.
Para esto es necesario actualizar el modelo que se tiene para
que efectivamente pueda manejar estas dificultades.
Haciendo uso del umbral de distancia $Thr_{D}$ para prevenir
malas actualizaciones, se realizan correciones al modelo,
en este caso, las funciones de distancia. Esto es, una distancia
menor a $Thr_{D}$ indica que el candidato pertenece a la misma clase,
mientras que una distancia mayor indica lo contrario. Utilizando
la ecuación \ref{eq:learning-model-update}, se agregan candidatos,
como muestras positivas de entrenamiento y cada 5 cuadros,
se utiliza el conjunto actualizado de entrenamiento para
reentrenar todas las funciones de distancia.

\begin{equation}
    \label{eq:learning-model-update-1}
    t_{label} = \left\{
                \begin{array}{l l}
                    1, & D_{S^{+}}(t) \leq Tht_{D}\\
                    0, & D_{S^{+}}(t) >  Tht_{D}
                \end{array} \right.
\end{equation}

\begin{equation}
    \label{eq:learning-model-update-1}
    D_{S^{+}}(t) = \dfrac{1}{N_{S^{+}}} \sum_{i \in S^{+}} D_{i}(t)
\end{equation}

En la ecuación \ref{eq:learning-model-update-2}, $N_{S^{+}}$ es el
número de muestras positivas de entrenamiento y $D_{S^{+}}(t)$
es el promedio de distancia del candidato $t$ a las muestras
de entrenamiento positivas.

\subsection{Graph based}
% IFTrace

El algoritmo conocido como \textit{IFTrace} \cite{IFTrace} tiene como objetivo demarcar un objeto en una secuencia de video. Este algoritmo hace mínimas
suposiciones sobre el objeto a seguir:

\begin{itemize}
    \item consiste de una o más regiones conexas,
    \item tiene un borde bien definido
    \item sus propiedades intrínsecas pueden variar con el tiempo.
\end{itemize}

Los objetos a seguir son inicialmente marcados de forma interactiva por el usuario en el primer cuadro, y luego se seleccionan automáticamente
varios marcadores en el interior y los alrededores del objeto. Estos marcadores se localizan en el siguiente cuadro utilizando en forma
conjunta el algoritmo de
seguimiento de características KLT \cite{KLT} y extrapolación de movimiento. Los bordes del objeto son entonces identificados a partir de estos marcadores por la IFT,
\textit{Image Foresting Transform}\cite{IFT}. Otra característica vital del algoritmo es el operador de detección de borde que se adapta gradualmente a cambios en el
color y la textura del objeto. \\

Al igual que otros métodos de segmentación de objetos basados en grafos, IFT trata a la imagen como un grafo, en el cual los píxeles son los nodos, y
estos están conectados mediantes aristas si son adyacentes y tiene un peso o costo. Este costo debe ser una medida de la probabilidad de que
los puntos estén separados por el borde del objeto de interés. En problemas sencillos puede ser tan simple como el valor absoluto de la diferencia de color
entre los píxeles. El método combina el gradiente del color con el gradiente de una función de clasificación de píxeles difusos, algo así como la similaridad entre el píxel
y el conjunto de píxeles del objeto segmentado en el frame anterior. \\

La IFT encuentra caminos de costo mínimo desde los marcadores, tanto internos como externos, a cada píxel de la imagen. Los píxeles son agrupados en particiones, que
resultan ser árboles de camino óptimo disjuntos,
\footnote{Dado un grafo simple, no dirigido y conexo G, un árbol de camino óptimo, o árbol de camino más corto, es un árbol recubridor de $G$, tal que la distancia o
costo del camino desde la raíz $v$ a cualquier otro vértice $u$ es la distancia de camino mínima de $v$ a $u$ en $G$.}
donde cada árbol tiene a uno de los marcadores como raíz. La proyección del objeto es entonces tomada como la union de los árboles cuyas raices
son marcadores internos.\\

\subsubsection{El algoritmo IFTrace}
\begin{algorithm}
    \caption{IFTrace}
    \label{alg:IFTrace-algorithm1-IFTrace}
    \begin{algorithmic}
        \Require\hspace{\algorithmicindent}\hspace{\algorithmicindent}Video I : D x \{1..$n_{f}$\} $\to V$
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm}donde D = \{1..$n_{x}$\} x \{1..$n_{y}$\}
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm}Mascara Binaria $O^{(1)}$ : D $\to$ \{0,1\}

        \Ensure \hspace{\algorithmicindent}\hspace{0.23cm} Mascaras Binarias $O^{(t)}$ : D $\to$ \{0,1\} para $t \in $ \{2..$n_f$\}
        \State

        \For{$t = 2,3, ..., n_f$}
            \State $(R^{(t-1)}_{o}$,$R^{(t-1)}_{x}) \gets $  SelectMarkers($I^{(t-1)}$,$O^{(t-1)}$)
            \State $(S^{(t)}_{o}$,$S^{(t)}_{x}) \gets$  TrackMarkers($R^{(t-1)}_{o}$,$R^{(t-1)}_{x}$,$I^{(t-1)}$,$I^{(t)}$)
            \If{$S^{(t)}_{o}$ $\neq \emptyset$}
                \State $O^{(t)} \gets$  IFTSegment($I^{(t)}, C^{(t-1)}, S^{(t)}_{o}, S^{(t)}_{x}$)
                \State$C^{(t)} \gets$ BuildClassifier($I^{(t)}$,$O^{(t)}$)
            \Else
                \State $C^{(t)} \gets C^{(t-1)}$
                \State $(O^{(t)}$,$C^{(t)}) \gets$  RecoverObj(I,t,O,C)
            \EndIf\EndFor
        \State \Return $O$
    \end{algorithmic}
\end{algorithm}


La figura \ref{alg:IFTrace-algorithm1-IFTrace} muestra el algoritmo de IFTrace desde el más alto nivel.
IFTrace toma como input un video $I$, modelado como un array 3D de píxeles, siendo las dimensiones el alto y ancho de la imagen, y número de cuadro de la secuencia de video, y una
máscara binaria $O^{(1)}$, correspondiente al objeto marcado en el primer cuadro, y devuelve un array de máscaras binarias $O^{(t)}$, con las
proyecciones del objeto para cada cuadro del video.

Para cada cuadro de la secuencia, el algoritmo elije dos conjuntos de puntos o píxeles: los que pertenecen a la máscara del objeto $R_{o}$, y los que pertenecen a
sus alrededores $R_{x}$. Luego se procede
a localizarlos en el siguiente cuadro a través del procedimiento \textit{trackMarkers}.

Si el conjunto de píxeles que representan al objeto $S_{0}^{(t)}$ no resulta vacío para este
nuevo cuadro, entonces el seguimiento
fue exitoso, y se procede a utilizar IFT para, a partir de los dos conjuntos de píxeles $S_{0}^{(t)}$ y $S_{x}^{(t)}$, el clasificador de color del cuadro anterior $C^{(t-1)}$
y el cuadro actual $I{(t)}$, obtener la máscara del
objeto para el cuadro actual $O{(t)}$. Esto es lo que hace el procedimiento \textit{IFTSegment}.

Como paso final, se obtiene el clasificador de color del cuadro actual $C{(t)}$, a partir de la máscara del objeto $O{(t)}$ y el cuadro actual $I{(t)}$.

Por otro lado, si el seguimiento del objeto falla para el nuevo cuadro, es decir si el conjunto de píxeles resultantes luego de aplicar \textit{trackMarkers} $S_{0}^{(t)}$
resulta vacío, entonces se mantiene el mismo clasificador de color del cuadro anterior $C{(t-1)}$, y se procede
a intentar recuperar el objeto en el cuadro actual mediante \textit{recoverObj}. Si la recuperación
es exitosa, se obtiene un máscara del objeto $O{(t)}$, y un clasificador de color para el cuadro actual $C{(t)}$,
sino, todos los conjuntos se dejan vacíos y el clasificador se mantiene inalterado.\

\subsubsection{Algoritmo RecoverObj}

\begin{algorithm}
    \caption{RecoverObj - Intento de recuperar un objeto perdido de vista}
    \label{alg:IFTrace-algorithm2-recoverObj}
    \begin{algorithmic}
        \Require\hspace{\algorithmicindent}\hspace{\algorithmicindent}Video $I$, indice de cuadro $t$, tope cuenta hacia atras $m_{f}$,
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm}mascaras del objeto $O^{k}$ y  clasificadores de colores $C^{k}$ para
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm}los $k$ cuadros previos.

        \Ensure \hspace{\algorithmicindent}\hspace{0.23cm} Mascara del objeto recuperada $O^{t}$ (puede estar vacia) y su
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm} correspondiente clasificador de color $C^{t}$
        \State

        \For{$k = t-1, t-2, ..., max{1, t-m_{f}}$}
            \If{$O^{k}$ no esta vacio}
                \State $M \gets $ CandidateMask($I^{(t)}, C^{(k)}$)
                \State Sea $\kappa$ la lista de regiones conexas en $M$
                \ForEach{region $K$ en $\kappa$}
                    \State ($S_{o}$,$S_{x} \gets$ SelectMarkers($I^{(k)},K$)
                    \State $K' \gets$ IFTSegment($I^{(t)}, C^{(k)}, S _{o}, S_{x}$)
                    \If{$K'$ es suficientemente similar a $O^{k}$}
                        \State $C' \gets$ BuildClassifier($I^{(1)}, O^{(1)}, D \ O^{(1)}$)
                        \State \Return ($K', C'$)
                    \EndIf
                \EndFor
            \EndIf
        \EndFor
        \State \Return ($\emptyset, \emptyset$)
    \end{algorithmic}
\end{algorithm}

Si en algún paso del algoritmo IFTrace, el seguimiento del objeto falla, se
procede a utilizar la heurística \textit{recoverObj} (Algoritmo \ref{alg:IFTrace-algorithm2-recoverObj}), que intenta localizar una
región conexa cuya forma y colores sea similar a la del objeto en alguno de los
cuadros anteriores.\\

La heurística se aplica utilizando un cuadro de referencia, e iterando hacia atrás
hasta encontrar un cuadro en el que se pueda recuperar el objeto, evitando
utilizar cuadros previos en los que no se pudo recuperar el objeto anteriormente.

Una vez ubicado el cuadro de referencia en el cual el seguimiento fue exitoso,
se construye una ``máscara candidata'' $M$ que indica las posibles ubicaciones
del objeto en el cuadro actual $t$. Esto es lo que hace el procedimiento \textit{CandidateMask}.
En este paso se
utiliza el clasificador de color del cuadro de referencia $k$, $C^{(k)}$. La máscara
etiqueta los píxeles del cuadro como ``posiblemente objeto''(1) o
``probablemente fondo''(0).

Esta máscara $M$ estará compuesta de cero
o más regiones conexas. Si el objeto está visible en el cuadro actual,
su proyección debería coincidir con alguna de estas regiones. Entonces
se procede a analizar cada una de estas regiones, para las cuales se obtienen
los dos conjuntos de marcadores $S_{0}^{(t)}$ y $S_{x}^{(t)}$, utilizando la misma técnica que en el
en algoritmo \ref{alg:IFTrace-algorithm1-IFTrace}.

 Luego se utiliza
nuevamente el algoritmo IFT para conseguir una proyección $K'$ de esa región $K$ que
se está analizando, para luego compararla con la máscara del objeto en el cuadro
$k$ utilizado como referencia. En caso de ser similar, se construye el clasificador
de color $C'$ y se retorna junto a la proyección $K'$ como máscara representativa
del objeto para el actual cuadro.

Cabe destacar que, por simplicidad, para la comparación de formas se utilizan
las Invariantes de Momento de Maitra \cite{MaitraMomentInvariants}, y las formas se consideran similares
si la distancia Euclideana entre sus vectores de invariantes es menor a 2.
Sin embargo se podría utilizar otros descriptores de formas.

Si ninguna de las regiones resulta similar a la máscara del objeto,
\textit{recoverObj} intenta el mismo procedimiento utilizando como cuadro de
referencia el cuadro anterior. Luego de un número especificado de intentos, o
de agotar todos los cuadros, la heurística termina. En este caso, se retorna
una máscara vacía y un clasificador nulo, señalando que el objeto se perdió en
el cuadro actual. \textit{IFTrace} intentará entonces recuperar en el siguiente
cuadro.

\subsubsection{Selección de Marcadores}
El procedimiento \textit{selectMarkers} es el encargado de elegir dos conjuntos
de marcadores $R_{0}^{(t)}$ y $R_{x}^{(t)}$, los que están dentro de la máscara del objeto, y los que están a
su alrededor.

Los marcadores internos se eligen aplicando una erosión morfológica
\footnote{La erosión morfológica es una de las dos operaciones fundamentales de la matemática morfológica. Consiste
en reducir o ``erosionar'' los bordes de un determinado objeto, reduciendo su tamaño. }
%TODO Mismo caso que morfological dilation, valdría la pena la refrencia a la wiki? O alguna imagen o ejemplo en un apendice?
 a la máscara del objeto, con radio $\delta_{o}$, y
luego seleccionando los píxeles de la región resultante que tengan mayor probabilidad
de ser seguidos por el algoritmo KLT. Específicamente, se construye la matriz:

\begin{equation}
    H[p] = \left[\begin{array}{cc}
                \sum_{q}(\frac{\partial L}{\partial x}[q])^2 & \sum_{q}(\frac{\partial L}{\partial x}[q])(\frac{\partial L}{\partial y}[q]) \\
                & \\
                \sum_{q}(\frac{\partial L}{\partial x}[q])(\frac{\partial L}{\partial y}[q]) & \sum_{q}(\frac{\partial L}{\partial y}[q])^2 \end{array}\right]
    \label{IFTrace-matrix-H}
\end{equation}


donde $L[p]$ es la luminancia del píxel $p$, y las sumatorias incluyen a todos los
píxeles $q$ en una ventana de $9x9$ centrada en $p$.\\
Se define el grado de ``igualdad'' $\lambda[p]$ como el valor mínimo singular de $H[p]$.
Solo los píxeles con $\lambda > 1$ son escogidos para utilizarlos en la
propagación KLT. Esto coincide con los autores Tomasi y Karade \cite{Tomasi91detectionand}
quienes afirman que los píxeles con mayor $\lambda$ tienen más posibilidades
de ser localizados por el algoritmo KLT.\\
Los marcadores externos son escogidos aplicando una dilatación morfológica,
\footnote{La dilatación morfológica es otra de las operaciones  básicas de la matématica morfológica. Generalmente utiliza un elemento
estructurador para expandir alguna forma contenida en la imagen.}
% TODO maybe poner refrencia a la wiki o la imagen del ejemplo en algun apendice?
%  Por ejemplo, si se utiliza un disco para dilatar un cuadrado, se logra un cuadrado mayor con los bordes redondeados
 con cierto radio $\delta_{x}$, y tomando los píxeles a lo largo del borde del resultado.

\subsubsection{Seguimiento de Marcadores}

El procedimiento \textit{trackMarkers} se utiliza para localizar los marcadores
internos en el cuadro actual, que se corresponden con los puntos internos del objeto
en el cuadro anterior. Utiliza el algoritmo de seguimiento KLT. descrito por Tomasi y
Karade \cite{Tomasi91detectionand}.

El algoritmo KLT recibe un punto $p$ en un cuadro $I^{t-1}$, una posición estimada
$q_{0}$ en el próximo cuadro $I^{t}$, y busca un punto $q$ tal que los vecinos
de $q$ en $I^{t}$ sean similares a los de $p$ en $I^{t-1}$. Este algoritmo tiene
varios parámetros de configuración que alteran su comportamiento: $\ell$, la cantidad
escalas consideradas; $\kappa$, el factor de reducción entre las sucesivas escalas; y
$\omega$, el ancho de la ventana usada para comparar vecinos en cada escala.
La implementación de IFTrace está configurada para usar $\ell=2$,$\kappa=4$ y
$\omega=9$, como en la implementación de KLT de Birchfield \cite{Birchfield-KLT-implementation}.

Los marcadores exteriores no son seguidos con KLT, ya que no tiene sentido debido
a que la mayoría se perdería por oclusión con el objeto o se seguiría el fondo, en
vez del objeto. En cambio, lo que se hace es trasladarlos de acuerdo a los
desplazamientos medios de los marcadores internos más cercanos. Esto tiende
a mantener estos marcadores fuera del objeto, pero cerca de su borde, aún cuando
hay rápidos cambios de tamaño o de forma (por ejemplo, rotaciones o movimiento de extremidades).

\subsubsection{Segmentación de objetos - IFT}

La IFT interpreta a la imagen $I$ como un grafo $G$, cuyos nodos son los píxeles y cuyas
aristas unen dos nodos si los píxeles que representan son adyacentes. IFT toma como parámetros un conjunto de
píxeles marcadores $S$, una función de costo de arista $w$, y una función de
conectividad $f$ que asigna un costo de camino $f(\pi)$ a todo camino $\pi$ in $G$,
dependiendo del costo de sus aristas.\\
Para cada píxel $p$, IFT encuentra un camino directo óptimo (de costo mínimo), que lo
conecta con su raíz $R(p)$ en el conjunto $S$ de píxeles marcadores. Estos caminos forman un bosque de caminos
óptimos. Cada árbol en este bosque de caminos óptimos
tiene como raíz a algun marcador $r$, y agrupa a todos los píxeles de la imagen que
están mejor conectados a $r$ que a cualquier otro marcador, es decir que su distancia a $r$ es menor
que su distancia a cualquier otro marcador. IFT también le asigna a
cada píxel $p$ un costo $V(p) = \pi(p)$, y un marcador raíz $R(p)$, el marcador
que se encuentra en la raíz del árbol al cual pertenece.

IFTrace depende de la IFT
para segmentar los objetos a trackear. Usa la función de conectividad $f_{max}$, que
asigna a un camino $\pi$ el máximo costo para todas las aritas en $\pi$.
Los píxeles marcadores utilizados son tanto los marcadores interiores, obtenidos
por el algoritmo KLT, como los exteriores que se ubican alrededor del objeto.

La segmentación obtenida al usar $f_{max}$ tiene una importante propiedad
\textit{minimax}. Sea la \textit{frontera} de una segmentación el conjunto de todas las aristas cuyos nodos
pertenecen a distintos segmentos, dicha segmentación maximiza el costo mínimo de todas las aristas en la frontera de la
segmentación. Esto significa que la segmentación IFT/$f_{max}$ es esencialmente
la misma que la famosa segmentación \textit{divisoria} \cite{watershed-segmentation}. Esto
hace que sea particularmente apropiada para casos en los que el objeto esté
mejor caracterizado por su conectividad que por su forma o tamaño. Es por esto que
se elige una función de costo de arista $w(p,q)$ que se base en la probabilidad de
que $p$ y $q$ estén en diferentes lados del borde del objeto.

\subsubsection{Algoritmo IFT}

Para algunas funciones de conectividad, como $f_{max}$, el bosque de caminos
óptimos se puede computar eficientemente mediante una variante del famoso
algoritmo de Dijkstra \cite{watershed-segmentation}. Por cuestiones de
eficiencia, el algoritmo retorna un mapa de raices $R$, que almacena, para
cada nodo $p$, su raíz $R(p)$.\\

\begin{algorithm}
    \caption{Algoritmo IFT con $f_{max}$}
    \label{fig:IFTrace-IFT-algorithm}
    \begin{algorithmic}
        \Require\hspace{\algorithmicindent}\hspace{\algorithmicindent}Grafo $G_{1}$, conjunto de semillas $S = S_{o} U S_{x}$

        \Ensure \hspace{\algorithmicindent}\hspace{0.23cm} Bosque de camino optimo $P$, mapa de conectividad $V$
        \State\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{0.3cm} y mapa de raiz $R$.

        \Auxiliary\hspace{\algorithmicindent} Cola de prioridades Q, variable $tmp$

        \State

        \ForEach{$p \in G_{1}$}
            \State $P(p) \gets$ nil, $R(p) \gets$ p, $V(p) \gets + \infty$
            \If{ $p \in S$} insertar $p$ en $Q$ y setear $V(p) \gets 0$ \EndIf
        \EndFor
        \While{$Q \neq \emptyset$}
            \State Remover $p$ de $Q$ tal que $V(p)$ sea minimo.
            \ForEach{$q$ 4-vecino de $p$, tal que $V(q) > V(p)$}
                \State Computar $tmp \gets max{V(p), w(p,q)}$
                \If{$tmp < V(q)$}
                    \If{$V(q) \neq + \infty$} remover $q$ de $Q$ \EndIf
                    \State $P(q) \gets p$, $R(q) \gets R(p)$, $V(q) \gets tmp$
                    \State Insertar $q$ en $Q$
                \EndIf
            \EndFor
        \EndWhile
    \end{algorithmic}
\end{algorithm}



Se agregan
los nodos que representan marcadores a la cola $Q$. El ciclo \textit{while}
principal computa un camino óptimo desde las raíces a cada nodo $p$. En
cada iteración, un camino de valor $V(p)$ mínimo se encuentra cuando
removemos el último píxel $p$ de la cola. Luego se evalua si el camino que
alcanza el píxel adyacente $q$ a través de $p$ es más barato que el actual
camino que termina en $q$ y se actualizan $Q$, $V(q)$, $R(q)$ y $P(q)$
acordemente.

Este algoritmo se puede modificar para recomputar el bosque de camino óptimo
en forma incremental, a medida que se van agregando o quitando marcadores,
generalmente en tiempo sub-lineal.

\subsubsection{Comparación con Corte de Grafos}
% Comparación con otros algoritmos de Graph-Cut

Boykov and Funka-Lea [5,12] han propuesto otra alternativa para la segmentación
% de imágenes basada en grafos, conocida como \textit{Graph-Cut}, que explota
de imágenes basada en grafos, conocida como Corte de Grafos, que explota
la conexión que existe entre cortes de capacidad mínima y flujos de volumen
máximo. En este enfoque, el grafo de píxeles se modela como una red de flujo,
donde el objeto es la fuente y el fondo el sumidero. Se puede probar que el máximo flujo total de todas las fuentes
hacia todos los sumideros es igual a la mínima capacidad total de todo corte
(conjunto de aristas) que separa fuentes de sumideros. Este flujo máximo y su
corte mínimo asociado se puede encontrar con el clásico algoritmo
Ford Fulkerson \cite{Cormen:2009:IAT:1614191}.

% En comparación con la IFT, \textit{Graph-Cut} tiene 2 grandes desventajas: es
En comparación con la IFT, \textit{Corte de Grafos} tiene 2 grandes desventajas:
tiene un mayor costo computacional (IFT es $O(n)$ mientras que
% el mejor algoritmo \textit{Graph-Cut} es $O(n^{2.5})$), y además tiende a
el mejor algoritmo \textit{Corte de Grafos} es $O(n^{2.5})$), y además tiende a
minimizar el número de aristas en el corte, en vez de sus capacidades. Esto
último quiere decir que muestra una preferencia a segmentar basada en la
longitud del borde, en lugar de basarse en la importancia de la conexión
entre el objeto y el fondo.\cite{journals/jmiv/MirandaF09}

% Se puede introducir una corrección al algoritmo de \textit{Graph-Cut} para
Se puede introducir una corrección al algoritmo de \textit{Corte de Grafos} para
remediar este segunda problema, pero lo único que se obtiene es el mismos
resultado de la IFT, con un costo computacional mucho mayor. \cite{journals/jmiv/MirandaF09}

\subsubsection{Costo de arista de IFT}

Como se explicó anteriormente, IFT opera con una función de costo de arista
$w$, la cual resulta crítica para la segmentación. Idealmente, el costo
para aristas que cruzan el borde del objeto debe ser alto, y bajo para todo
el resto. En otras palabras, la función de costo debe ser un detector
de bordes del objeto.

Un ejemplo puede ser la distancia Euclideana entre los colores RGB de los píxeles
en ambos extremos de una arista. Desafortunadamente, este detector resulta demasiado
simplista para casos prácticos, en los que un objeto puede tener diferentes colores y
texturas. Por lo tanto, se requieren detectores de bordes más sofisticados.

En la implementación de \textit{IFTrace}, se utiliza un detector de bordes basado en
una combinación lineal

\begin{equation}
   \label{eq:IFTrace-edge-detector}
   w(p,q) = \gamma w_{f}(p,q) + (1 - \gamma)w_{0}(p,q) = \gamma |\nabla I| + (1 - \gamma)|\nabla M|
\end{equation}

donde $\gamma$ es un parámetro definido por el usuario, $\nabla I$ es el gradiente
del color de la imagen y $M$ es un mapa de clasificación de color.

La primer componente $w_{f}(p,q)$ es la distancia Euclideana entre los colores de
los extremos de la arista, como se menciona anteriormente pero con una particularidad:
se mide en el espacio de colores $Lab$ de $CIE$
\footnote{
Un espacio de colores \textit{Lab} es un espacio de colores de 3 dimensiones, $L$ para la luminosidad o claridad, $a$ para la posición entre rojo y verde y
$b$ para su posición entre amarillo y azul. Existen dos espacios muy similares \textit{Hunter Lab} y \textit{CIE Lab}, que se diferencian en la forma de
calcular las coordenadas de color a partir de los datos: el primero utiliza raíces cuadradas y el segundo raíces cúbicas.}
, en vez del tradicional RGB. La
justificación para esto es que las distancias entre colores se aprecian más de
esta forma. %TODO VER TEMA DE CIELAB y references

El segundo componente $w_{o}(p,q)$, es el gradiente del mapa de clasificación
de colores $M$, una imagen en escala de grises donde cada píxel $M[p]$ es
la probabilidad de que un píxel con color $v=I[p]$ pertenezca a la proyección
del objeto. Los colores que ocurran solo dentro del objeto deberían estar
asociados al valor 1, los que solo ocurran en el fondo deberían estar
asociados al 0, y los que puedan ocurrir en ambos, deberían mapearse a
valores intermedios. El propósito de incluir este término es restarle
importancia a los bordes entre colores que son internos del objeto, o
totalmente ajenos al objeto, y enfatizar los bordes que efectivamente
delimitan el objeto del fondo de la imagen.

El mapa de clasificación de colores $M$ se obtiene de la imagen $I$ por medio de un
clasificador de color difuso $C$, una función no lineal $C : \mathbb{V} \to [0,1]$.
En \textit{IFTrace}, la función $C$ se implementa como una variante del clasificador
del vecino más cercano, \textit{nearest neighbor} (NN). Esta determinada por dos conjuntos de
colores, que se asumen son representativos del objeto de interés y del fondo, respectivamente.Para evaluar $C(v)$ para
cierto color $v$, se debe buscar 2 colores representantes $u_{0} \in \mathbb{U}_{0}$
y $u_{x} \in \mathbb{U}_{x}$ que son los más cercanos a $v$.
La probabilidad de que un píxel de color $v$ sea parte del objeto es entonces estimada
por la fórmula

\begin{equation}
   \label{eq:IFTrace-color-classifier}
   C(v) = \frac{|v - u_{0}|}{|v - u_{0}| + |v - u_{x}|}
\end{equation}

En teoría, se podría usar todos los píxeles para construir los conjuntos
$\mathbb{U}_{0}$ y $\mathbb{U}_{x}$. Pero en la práctica, se deben usar muestras
de menor tamaño por razones eficiencia, de otra forma, el costo de encontrar los
representantes $u_{0},u_{x}$ aumenta demasiado. De hecho, la construcción del mapa
$M$ resulta ser el paso que tiene mayor costo computacional de \textit{IFTrace}, más
aún que el seguimiento de marcadores y que la segmentación de la IFT.

Es por esto que el procedimiento para construir el clasificador,
\textit{buildClassifier}, comienza seleccionando dos conjuntos de píxeles
$R_{0},R_{x}$, respectivamente los que están dentro y fuera de la actual máscara
del objeto. Pero si alguno de estos conjuntos tiene más de 200 elementos,
entonces se realiza un muestreo aleatorio para reducirlos a ese tamaño.

\subsection{Contornos Activo}

La segmentación basada en contornos activos se basa principalmente, como su nombre lo indica, en el contorno de una determinada 
regione o regiones de interés. Se define una región como distribución $p(\Theta(x))$, donde $x$ es un pixel y $\Theta = \{\theta_{1}, ..., \theta_{n}\}$ es el
vector característico definido para cada pixel. El vector característico es un conjunto de características distintivas. Puede ser el color promedio en la muestra de
pixeles de la región, los parámetros estimados de una región utilizando un modelo estadístico, etc.
 Teniendo esto en cuenta, un objeto, como por ejemplo el objeto de interés, queda caracterizado por un conjunto de parámetros $\Theta$.

El borde de una región se representa por una curva paramétrica dada por:

\begin{equation}
    C(s) = (x(s), y(s))
\end{equation}

donde $0 \leq s \leq S$, $C(0) = C(S)$.

Pero la curva evoluciona y cambia con el transcurso del tiempo. Sea $F(s)$ la fuerza que incide sobre el objeto y provoca el cambio en la curva, la ecuación
de la curva se puede definir, en el transcurso del tiempo como


\begin{equation}
    C(s,t) = (x(s), y(s), t)
\end{equation}

donde $0 \leq s \leq S$, $C(0,t) = C(S,t)$, y $t$ es la variable del tiempo.

\begin{eqnarray}
    C(s,t) &=& \overrightarrow{N}_{C(s,t)}F(s)\\
    C(s,0) &=& C_{0}(s)\\
\end{eqnarray}

donde $\overrightarrow{N}_{C(s,t)}$ es el vector normal de $C(s,t)$ y $ C_{0}(s)$ es la curva inicial.

Dentro de la fuerza $F(s)$, se distinguen dos fuerzas $F_{d}$ y $F_{s}$. $F_{d}$ es la velocidad de evolución y $F_{s}$ es una fuerza que suaviza la curva.
$F_{d}$ se puede modelar como 

\begin{equation}
    F_{d}(x) = log(p(\Theta^{i}(x) | \Omega_{i}) / p(\Theta^{j}(x) | \Omega_{j}))
\end{equation}

donde $\Theta^{i}$ y $\Theta^{j}$ son los vectores característicos de las regiones $\Omega_{i}$ y $\Omega_{j}$ respectivamente.

Por otro lado, $F_{s}$ tiene la forma

\begin{equation}
    \label{eq:active-contours-fs}
    F_{s}(x) = -2\lambda\kappa(x)
\end{equation}

donde $\kappa$ es la curvatura.

Existe otra formulación del problema de evolución de curvas, que consiste en representar la curva como el nivel cero de
una superficie $\phi$.

% TODO Poner referencia Conjuntos de Nivel (Osher y Sethian en 1988) y maybe un footnote

\subsection{Implementación Numérica}

En la implementación, el borde se representa usando dos conjuntos de píxeles correspondientes a los bordes interno y externo, $L_{in}$ y $L_{out}$ respectivamente. 
Entonces, la evolución se realiza intercambiando píxeles entre estos dos conjuntos.

A continuación se detalla el enfoque para la segmentación de un solo objeto de interés pero se puede fácilmente extrapolar y 
utilizar esta técnica para la segmentación de múltiples objetos.

%TODO maybe footnote aclarando como? Basta con marcar cada region con un identificador distinto

El objeto de interés $\Omega_{1}$ y el fondo $\Omega_{0}$ cumplen $\Omega_{1}\cup\Omega_{0} = I_{k}$ donde $I_{k}$ es la imagen del cuadro $k$ de la secuencia de imágenes, y
$\Omega_{1}\cap\Omega_{0} = \emptyset$. Cada una de las regiones está caracterizada por el vector característico $\Theta_{m}, m = \{0,1\}$

La función $\phi$  se define como

\begin{equation}
\phi(x) =
\left\{
    \begin{array}{ll}
        3  & \mbox{if } x \in \Omega_{0} \mbox{  and  } x \notin L_{out} \\
        1  & \mbox{if } x \in L_{out}\\
        -1  & \mbox{if } x \in L_{in}\\
        -3 & \mbox{if } x \in \Omega_{1} \mbox{  and  } x \notin L_{in} \\
    \end{array}
\right. 
\end{equation}

Los conjuntos $L_{in}$ y $L_{out}$ se definen

\begin{equation}
    L_{in} = {x \mbox{ es un pixel }| \phi(x) < 0 \mbox{ and } \exists y \in N_{4}(x) \mbox{such that } \phi(y) > 0}
\end{equation}

\begin{equation}
    L_{out} = {x \mbox{ es un pixel }| \phi(x) > 0 \mbox{ and } \exists y \in N_{4}(x) \mbox{such that } \phi(y) < 0}
\end{equation}

donde $N_{4}(x) = { y \mbox{ es un pixel } | |x-y| = 1}$, son los píxeles vecinos de un píxel $x$.

El algoritmo de segmentación es un algoritmo de dos ciclos, ya que luego de la especificación inicial de la curva en forma supervisada
\footnote{Podría no ser supervisada. Existen variantes con determinaciones semi-supervisadas del objeto de interés, así como también detección automáticas
basadas en ciertas características predefinidas.}
se intercambian los píxeles de $L_{in}$ y $L_{out}$ en dos ciclos. En el primero, se aplica la fuerza $F_{d}(x)$, y en el segundo se aplica $F_{s}(x)$ para la regularización.

En el primer ciclo, se ejecutan los siguientes pasos $N_{a}$ veces, donde $ 0 < N_{a} < max(filas, columnas)$.

\begin{enumerate}
    \item Para cada $x \in L_{out}$, si $F_{d}(x) > 0$ entonces borrar $x$ de $L_{out}$ y agregarlo a $L_{in}$.
    Luego, $\forall y \in N_{4}(x)$, con $\phi(y) = 3$, agregar $y$ to $L_{out}$ y hacer $\phi(y) = 1$.

    \item Después del paso 1 algunos de los píxeles $x$ en $L_{in}$ pasan a ser píxeles internos y por lo tanto 
    se sacan de $L_{in}$ y se hacer $\phi(x) = -3$.

    \item Para cada $x \in L_{in}$ , si $F_{d}(x) < 0$ entonces, borra $x$ de $L_{in}$ y agregarlo a $L_{out}$. Luego, 
     $\forall y \in N_{4}(x)$, con $\phi(y) = -3$, agregar $y$ a $L_{in}$ y a hacer $\phi(y) = -1$.


    \item Después del paso 3 algunos de los píxeles $x$ en $L_{out}$ pasan a ser píxeles externos y por lo tanto 
    se sacan de $L_{out}$ y se hacer $\phi(x) = 3$.
\end{enumerate}

%TODO agregar pseudocode

En el segundo ciclo, la curva se suaviza utilizando un filtro Gaussiano, de tal forma que la fuerza de evolución es $F_{s}(x) = G \otimes \phi(x)$, 
que imita el comportamiento de la evolución de la curva que muestra la ecuación \ref{eq:active-contours-fs}.

En cada cuadro, el borde del contorno del objeto se halla utilizando una curva inicial, el resultado de obtenido por el algoritmo en el cuadro anterior. En el 
caso de la primera imagen, se puede dar de forma supervisada o semi-supervisada por el usuario, o también puede ser obtenida de forma automática, mediante 
algoritmos de aprendizaje complejos basados en características predefinidas.

El algoritmo termina cuando se alcanza la condición de corte, dada por las ecuaciones \ref{eq:active-contours-stoppingCondition} o cuando se alcanza el final de 
la secuencia de imágenes.

\begin{equation}
\label{eq:active-contours-stoppingCondition}
    \begin{array}{ll}
        F_{d}(x) \leq 0 & \forall x \in L_{out}\\
        F_{d}(x) \leq 0 & \forall x \in L_{in}
    \end{array} 
\end{equation}

\section{Analisis de deportes con 6 camaras}
\label{sec:6-camaras}

% Tanos

\section{Analisis de deportes con 8 camaras}
\label{sec:8-camaras}

\citeauthor*{xu-8cams} proponen un sistema que consta de 8 cámaras conectadas a
sistemas que analizan la información y a través de una capa de red envían la
información a un supervisor, encargado del mantenimiento de la posición de los
jugadores. El sistema supervisor no tiene acceso a los datos crudos de la
imágen obtenida.

Cada cámara realiza un preprocesamiento de la imágen para estimar la posición
de la cámara y detectar áreas de interés (candidatos a ser los jugadores en
pantalla). Para la eliminación del fondo, se utilizan dos máscaras, una
geométrica, que se aproxima a la geometría de la cancha y una que extrae
información acerca de los píxeles y genera un histograma para detectar el color
verde del pasto de la cancha. Para la primera máscara, se pasa la imágen de
\textit{RGB} a \textit{HSI} y se analiza el histograma de \textit{hue} para los
mayores valores de intensidad. Luego, los píxeles que serán considerados son
aquellos que no pertenezcan a un rango de \textit{hue} entre un mínimo y un
máximo, correspondientes a los valores que hagan que el máximo valor del
histograma caiga al 10\% de su valor original.  Luego, la máscara que elimina
valores de acuerdo a su color queda definida por:

\[
  M_c = ({(u, v) | H(u, v) \in [H_l, H_h]} \oplus B ) \ominus B
\]

Donde $H(u, v)$ es el valor de \textit{hue} del píxel en la posición $(u, v)$,
$B$ es un elemento estructurador cuadrado y $\oplus$ y $\ominus$ son los
operadores morfológicos de erosión y dilatación, aplicados para separar a los
jugadores y eliminar las líneas de campo blancas. La máscara geométrica
comprende los siguientes puntos:

\[
  M_g = { (u, v) | E(u, v)  \in P }
\]

Donde P es el rango de coordenadas en el mundo real correspondiente a la cancha
y $E(u, v)$ es la correspondencia del punto $(u, v)$ en el mundo real, de
acuerdo a una corrección utilizando ángulos de Euler. Por último la máscara que
determina aquellos pixeles que corresponden al pasto de la cancha son los que
pertenecen a la intersección de ambas máscaras:

\[
  M = M_c \cap M_g
\]

Las \textit{bounding boxes} de los objetos candidatos a ser jugadores son
representadas por la posición en el plano de la imágen $\mathbf{x}_l$ y su
error en la medición $\mathbf{z}_l$ en un filtro de Kalman:

\[
\mathbf{x}_l = [r_c \; c_c \;  \mathbf{\dot r}_c  \; \mathbf{\dot c}_c \;  \Delta r_1  \; \Delta c_1 \;  \Delta r_2 \;  \Delta c_2]^T
\]

\[
\mathbf{z}_l = [r_c \;  c_c  \; r_1  \; c_1  \; r_2  \; c_2]^T
\]

Donde $r_1 < r_2$ y $c_1 < c_2$ son los límites de la \textit{bounding box} y
$r_c$ y $c_c$ son los centroides de la \textit{bounding box}. Estos valores son
actualizados cuadro por cuadro, asumiendo que la variación en alto y ancho es
baja. Se utilizan ángulos de Euler para traducir estos valores a la posición
esperada dentro del plano de la cancha. La varianza es estimada utilizando el
jacobiano de la matriz de Euler. Por último, se analiza la categoría de los
jugadores de acuerdo al histograma de colores, clasificando de acuerdo a los
cinco posibles uniformes (uno para cada equipo, uno para cada arquero, y los
árbitros).

El módulo supervisor recibe de cada computadora los datos preprocesados y
ninguna información acerca de las imágenes. Se unifican los valores obtenidos
de todos los módulos y se los asocia utilizando una matriz que es actualizada
de acuerdo a la distancia de Mahalanobis. Si esta distancia queda por debajo de
un determinado umbral, se empieza a considerar que las mediciones de dos
cámaras distintas para dos \textit{bounding boxes} pasan a ser el mismo
jugador.

\section{Analisis de deportes con multiples camaras}
\label{sec:var-camaras}

% SIFT Base blablablabla
\subsection{Camera-based Observation of Football Games for Analyzing Multi-agent Activities}

\citeauthor*{beetz-05} analizaron, desde el punto de vista de la inteligencia
artificial, el problema de detectar el comportamiento de los jugadores dentro
de la cancha. Para eso, propusieron un sistema con dos módulos, uno que extrae
características e información de videos provenientes de un número de cámaras, y
un módulo de análisis y seguimiento del comportamiento de cada objeto (un
sector candidato de la imágen a contener a la pelota o a una persona en el campo de
juego, llamado \textit{blob} en el trabajo).

Respecto al módulo que extrae características, encontraron una gran dificultad
en detectar la posición de jugadores más alejados de la cámara, dado que el
material con el que trabajaron en general eran cámaras situadas a no más de 18
metros de altura. Esto hacía que la resolución en el lateral opuesto de la
cancha sea de 1,5 metros por píxel, insuficiente para hacer un análisis real de
la información obtenida.

Como parte del trabajo se encuentra la detección de sectores y líneas en la
cancha, las líneas blancas que demarcan sectores importantes del campo de
juego, y los distintos tonos de verde en franjas que es frecuentemente el caso
del césped de estadios de Europa. Esta característica no se vé en las canchas
de fútbol en la mayoría de los países de América Latina.

Para mantener información acerca del movimiento sobre el eje de la cámara
(denominado \textit{panning}), se utiliza un algoritmo de aprendizaje basado en
\textit{KLT} para detectar características en los carteles publicitarios
usualmente presentes en los laterales de la cancha. Esto ayuda a la robustez
del algoritmo, pero en ciertos casos no es suficiente, como sucede cuando el
camarógrafo mueve la cámara rápidamente para no perder de vista la pelota en el
caso de un pase largo. El estudio reporta que no se pudo mantener el seguimiento
correcto de la orientación y posición de la cámara por más de 2,5 minutos.

El análisis del video se compone de las siguientes etapas:

\begin{itemize}

  \item \textbf{Segmentación por color}: Se diferencia el verde de la cancha,
    los jugadores, la publicidad de fondo, y las líneas blancas de la cancha
    mediante el color de los mismos. Debido a diferencias de iluminación, se
    actualizan los parámetros para la detección de valores que corresponden al
    pasto verde de acuerdo a un algoritmo de aprendizaje que es sensible al
    ángulo estimado de la cámara y al tiempo.

  \item \textbf{Estimación de la posición de la cámara}: Se tiene un modelo de
    los bordes rectos que debieran detectarse en la cámara, y sus posiciones en
    tres dimensiones. A partir de esto, se obtienen datos acerca de la
    perspectiva. Para fortalecer la detección, se corrigen las posiciones
    utilizando un algoritmo de aprendizaje que toma como entrada las
    publicidades que se ven en el extremo opuesto de la cancha.

  \item \textbf{Detección de \textit{blobs}}: Otros objetos que no sean verdes
    o blancos (pasto o líneas de la cancha) son candidatos a ser jugadores o el
    árbitro. Estos son segmentados y analizados en busca de ciertas
    particularidades: se espera que en general sean más altos que anchos, con
    segmentos definidos: segmentos diferenciados por color correspondientes al
    pelo, camisa, piernas, que son aprendidos y actualizados a lo largo del
    análisis.

\end{itemize}

Luego del análisis de características del video, el procesamiento y seguimiento
de los jugadores es realizado utilizando una extensión del algoritmo
\textbf{Multiple Hypothesis Tracking(MHT)} \cite{MHT-1, MHT-2} mejorado por
\citeauthor*{Schmitt-1}\cite{Schmitt-2}. Este algoritmo utiliza un modelo de
cámara y movimiento probabilístico para estimar la posición de los jugadores y
actualizarlas en cada observación. Se utilizan muchas hipótesis propias de las
características de un partido de fútbol para mejorar esta estimación:

\begin{itemize}
  \item \textbf{Trackeo de personas}: No se dá el caso de que un jugador
    desaparezca de la cancha de un \textit{frame} a otro. Aparecen gradualmente
    desde el borde del campo de visión.

  \item \textbf{Oclusiones entre jugadores}: No se descarta la información
    sobre la estimación de un jugador cuando éste pasa a estar ocluído por otro
    jugador.

  \item \textbf{Jugadores sobre un plano}: Se asume que la cancha es un plano
    tridimencional y que los jugadores están posicionados sobre este plano.
    Esto además permite relacionar el tamaño de los \textit{blobs} con la
    cercanía del jugador a la cámara.

\end{itemize}

Por último, este análisis genera información de alto nivel semántico:
\textit{movimientos} de la pelota y \textit{episodios}. Para modelar los
movimientos de la pelota, se modeló la posición de la pelota como una función
lineal por partes. Un episodio es definido como la secuencia de
\textit{movimientos} de la pelota desde que un jugador toma control de ella
hasta que lo pierde. Los movimientos exitosos que un jugador ejecuta en este
modelo son pases, tiros al arco, o cambios bruscos de dirección (llamado
\textit{dribbling} por los autores).

\section{Analisis de deportes con video televizado}
\label{sec:tv-video}

\subsection{\citetitle{LIU20061146}}

En \cite{LIU20061146} se plantea una tecnica para obtener las posiciones de los jugadores y la pelota utilizando la transmision televizada de un partido de futbol.
El algoritmo se puede dividir en los siguientes grandes rasgos:
\begin{itemize}
\item Estimacion de la relacion entre puntos en la imagen y coordenadas en la cancha
\item Estimacion de la posicion de la camara en las coordenadas del mundo
\item Deteccion y tracking de la pelota
\item Deteccion de la cancha
\item Deteccion de los jugadores
\end{itemize}

Para estimar la relacion entre los puntos en la imagen y las coordenadas en la cancha se calcula una homografia.
Siendo $M = (x, y, 1)$ un punto en el plano de la cancha en coordenadas homogeneas y $m = (u, v, 1)$ la posicion del punto en la imagen, se puede convertir $ m = H M $.

Como la perspectiva de la camara cambia cuadro a cuadro, esta debe ser calculada en cada cuadro nuevamente.
Si en la imagen actual se encuentran 4 puntos conocidos (Esquinas de la cancha o de las areas), la homografia puede ser calculada directamente.
De no ser asi, se estima considerando que la homografia del cuadro actual $H_t$ se puede relacionar con $H_{t-1}$ mediante un \textit{Global Motion Parameter} $P$.
Este parametro $P_{t-1,t}$ se calcula tomando una serie de puntos en la imagen y relacionando su posicion entre el cuadro $t-1$ y $t$.
Luego $ H_t = H_{t-1} P_{t-1,t}$.

Para obtener la posicion de la camara se descompone la homografia en 2 matrices:
\begin{equation}
H = K \begin{bmatrix} r_1 & r_2 & t \end{bmatrix}
K = \begin{pmatrix}
    \alpha & \gamma & u_0 \\
    0 & \beta & v_0 \\
    0 & 0 & 1
    \end{pmatrix}
\end{equation}

Donde $\alpha$, $\beta$ representan la amplitud focal de la camara, $\gamma$ representa el \textit{skew} y $(u_0, v_0)$ es la coordenada del punto principal.
Se asume que la amplitud focal se mantiene constante, $\gamma = 0$ y el punto principal es el centro de la imagen.
$r_1$, $r_2$ son parte de una rotacion $R = (r_1, r_2, r_1 \times r_2)$, y $t$ son las coordenadas del origen de la cancha en coordenadas de la imagen.
Conocidas $H$ y $K$ se puede calcular la posicion de la camara como $R^{-1} t$.
Para el calculo de $K$ se necesita $\alpha$ y $\beta$ que se calcula usando $P$ de la siguiente manera:

\begin{equation}
\begin{bmatrix}
    p_{1 1} p_{2 1} & p_{1 2} p_{2 2} \\
    p_{1 1} p_{3 1} & p_{1 2} p_{3 2} \\
    p_{1 1} p_{3 1} & p_{2 2} p_{3 2}
\end{bmatrix}
\begin{bmatrix}
    \alpha^2 \\
    \beta^2
\end{bmatrix}
 =
\begin{bmatrix}
    - p_{1 3} p_{2 3} \\
    - p_{1 3} p_{3 3} \\
    - p_{2 3} p_{3 3} \\
\end{bmatrix}
\end{equation}

Se usa el metodo \textit{KLT} \cite{KLT} para encontrar los puntos de referencia a seguir para el calculo de $P$.

\subsubsection*{Seguimiento de la pelota}

El algoritmo planteado para seguimiento de la pelota tiene 2 etapas.
La primer etapa es de deteccion utilizando un algoritmo basado en \textit{Viterbi}.
La segunda etapa es de seguimiento utilizando un \textit{Kalman Filter}.

Para deteccion se crea una imagen binaria, segmentando segun la caracteristica blanca de la pelota.
Una vez segmentada, se eliminan los candidatos teniendo en cuenta las distintas caracteristicas morfologicas de la pelota.
Esta operacion se realiza en $T$ cuadros distintos, a partir de esto se construye un grafo pesado.
Los nodos de este grafo representan candidatos, con un peso segun que tan parecidos son a una pelota ideal.
Y los vertices se colocan si estan a una cierta proximidad y pesados segun que tan cerca y parecidos sean los nodos.
Sobre este grafo se hace una busqueda de camino optimo, y de este la posicion de la pelota en el ultimo cuadro.

Una vez detectada la pelota, se utiliza tracking hasta que no se confia en el resultado del algoritmo de tracking.
En esa instancia se vuelve a detectar la pelota con el algoritmo dicho anteriormente.

\subsubsection*{Deteccion de la cancha}

Para detectar la cancha y aislar el resto de los objetos, se computa un histograma de colores de la imagen.
Los autores consideran que el color de la cancha representa el mayor pico en el histograma.
Por lo tanto, buscan este pico en el histograma y toman todos los colores adyacentes en el histograma que esten dentro de un rango de ocurrencia relativo al pico principal.

\subsubsection*{Deteccion de jugadores}

Una vez que se determinó el rango de colores de la cancha, se construye una imagen binaria separando la cancha de todo otro objeto.
Construida esta imagen, se aplica la misma tecnica que se usa para seguir la pelota, adaptada a la morfologia de los jugadores.
Como se conoce la posicion en la imagen de los jugadores, y la homografia $H_t$ se puede calcular la posicion real de los jugadores en ese cuadro fácilmente.

\printbibliography

\end{document}
