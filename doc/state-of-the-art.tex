\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[spanish]{babel}
\usepackage[pdftex,usenames,dvipsnames]{color}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage[small,bf]{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{titlesec}
\usepackage{csquotes}
\usepackage[backend=bibtex]{biblatex}
\usepackage{titling}

\DeclareMathOperator*{\argmin}{arg\,min}
\addbibresource{references}
\DeclareFieldFormat[inbook]{citetitle}{#1}

\titleformat{\section}{\small\center\bfseries}{\thesection.}{0.5em}{\normalsize\uppercase}
\titleformat{\subsection}{\small\center\bfseries}{}{0.5em}{\small\uppercase}

\def\customabstract{\vspace{.5em}
    {\small\center{\textbf{RESUMEN}} \\[0.5em] \relax%
    }}
\def\endkeywords{\par}

\def\keywords{\vspace{.5em}
    {\textit{Palabras clave: } 
    }}
\def\endkeywords{\par}

% TITLE Configuration
\setlength{\droptitle}{-30pt}
\pretitle{\begin{center}\Huge\begin{rmfamily}}
\posttitle{\par\end{rmfamily}\end{center}\vskip 0.5em}
\preauthor{\begin{center}
        \large \lineskip 0.5em%
\begin{tabular}[t]{c}}
\postauthor{\end{tabular}\normalsize 
    \\[1em] Estudiantes del Instituto Tecnológico de Buenos Aires
\par\end{center}}
\predate{\begin{center}\small}
\postdate{\par\end{center}}

% Headers
\addtolength{\voffset}{-40pt}
\addtolength{\textheight}{80pt}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\lhead{\small No publicado}
\rhead{\small \thepage}
\cfoot{\small Copyright \copyright 2013 ITBA}

% Metadata
\title{}
\date{20 de Septiembre de 2013}
\author{Civile, Juan Pablo \and Crespo, Álvaro \and Ordano, Esteban }

\begin{document}

\pagestyle{fancy}
\maketitle
\thispagestyle{fancy}

\begin{customabstract}
\textbf{
Las técnicas de seguimiento de objetos en videos tienen numerosas aplicaciones
en las actividades cotidianas. En el ámbito deportivo pueden ser útiles para
soportar (o hasta reemplazar) las decisiones de los jueces o árbitros del
juego, permitir a los deportistas mejorar su juego mediante el análisis de sus
movimientos, otorgar estadísticas y métricas a los fanáticos del deporte, entre
otras aplicaciones. Se describe a lo largo de este trabajo técnicas
aplicables al problema de seguimiento de múltiples jugadores de fútbol
mediantes el uso de una o varias cámaras de video. Se presentan brevemente sus
bases matemáticas y se analizarán características de cada una junto con las
limitaciones y la factibilidad de obtener todas las posiciones del juego a
partir de su implementación.
} \end{customabstract}

\newpage

\part*{Introducción}

% TODO: No me gustó como quedó la parte de "que se conocen"
En una primer sección se describirán los algoritmos de seguimiento
de objetos que se conocen,
% TODO: No se si 'divididos' es la palabra correcta
divididos en cuatro familias estudiadas:
\textit{Predictores Lineales},
\textit{Aprendizaje Lineal},
\textit{Corte de Grafos},
y \textit{Contornos Activos}.

% TODO: Armar referencia a la sección 2?
En la sección dos se discutirán los avances que se han hecho y los sistemas
implementados que resuelven el problema de seguimiento de jugadores y pelota en
una cancha de fútbol. Se describirán también las técnicas con mayor nivel
semántico que detectan movimientos de jugadores, pases de pelota, tiros al
arco, entre otros. Se dividen los mismos categorizados por los sistemas de
cámaras utilizadas (una sola cámara fija, video televizado, o múltiples cámaras
fijas).

\newpage

\part*{Estado del Arte}

Comenzamos por describir algoritmos de seguimiento de objetos en videos en la
seccion \ref{sec:tracking}.  Luego analizamos técnicas utilizadas para el
analisis de deportes, clasificándolas según el número de cámaras utilizadas.
Primero 6 camaras en la seccion \ref{sec:6-camaras}, 8 camaras en la seccion
\ref{sec:8-camaras}, multiples camaras en \ref{sec:var-camaras} y finalmente
video televizado en \ref{sec:tv-video}.

\section{Algoritmos de seguimiento}
\label{sec:tracking}

Conocemos 4 familias de algoritmos de seguimiento en video.
Pasamos a describir las tecnicas usadas por estos.

\subsection{Predictores Lineales}

Un \textit{Predictor Lineal} es una funcion que toma los valores de una serie
de variables aleatorias y predice el valor de una variable dependiente.  La
funcion tiene la forma $f(x_1, ..., x_n) = \beta_0 + \beta_1 x_1 + \dots +
\beta_n x_n$, donde $x_i$ es una variable aleatoria y $\beta_i$ una constante.
Se dice que el predictor es lineal al obligarse a $\beta_i$ a existir en los
numeros reales.

En \cite{alp, original-linear-predictors} los autores utilizan predictores para
hacer seguimiento de objetos en video.  El objetivo es relacionar el cambio de
valor de varios pixeles cuadro a cuadro con el movimiento del objeto entre
dichos cuadros.  Para soportar cualquier clase de movimiento, este se
representa mediante una homografia (\cite{homography-estimation}), $H \in
R^{3,3}$.

Entonces los predictores se representan mediante una matriz $A \in
\mathbb{R}^{9xn}$ donde cada fila representa una funcion de prediccion.  De 2
cuadros consecutivos se obtiene el vector de cambios de valor de pixeles $X =
(x_1, \dots, x_n)$ y se computa:

\begin{eqnarray*}
    AX = B \\
    B = (h_{1,1}, h_{1,2}, h_{1,3}, h_{2,1}, h_{2,2}, h_{2,3}, h_{3,1}, h_{3,2}, h_{3,3})
\end{eqnarray*}

Donde $B$ contiene los valores de la homografia ($H$) de movimiento entre los cuadros.

\subsubsection{Calculo de los predictores}
% TODO: Aclarar que es perturbar
% TODO: Aclarar que el calculo de la homografia de la perturbacion es directa
Para obtener la relacion $A$ se utiliza un paso inicial de entrenamiento.
Primero se determina la posicion del objeto en un cuadro de manera supervisada.
Una vez conocida la posicion, se toman $n$ muestras de valores de pixeles en ese cuadro.

Luego se crean $m$ perturbaciones de la posicion del objeto, y se computa la homografia $H_i$ que representa esa perturbacion.
Llamemos al vector que representa esa homografia $B_i$.
Ademas, tomamos muestras de valores de pixeles ($X_i$) con sus posiciones alteradas por la homografia $H_i$.
Se puede entonces plantear:
\begin{equation}
    A \left( X_1 \lvert \dots \lvert X_m \right) = \left( B_1 \lvert \dots \lvert B_m \right)
\end{equation}
Que es un sistema de ecuaciones lineales que puede ser resulto de manera sencilla.

\subsubsection{Mejoras}

Para mejorar la efectividad de los algoritmos, se calculan varios predictores y se disponen en capas.
Cada capa se construye para buscar cambios de posicion cada vez mas pequeños.
Es decir, la primer capa busca cambios bruscos y la ultima pequeños cambios.

\citeauthor*{alp} (\cite{alp}) introducen manejo de oclusiones parciales de manera eficiente.
Para esto se divide el objeto en pequeñas secciones cuadradas, llamadas \textit{templates}, y se computa la matriz $A$ de la siguiente manera:
\begin{eqnarray*}
    Y &=& \left( B_1 \lvert \dots \lvert B_m \right) \\
    H &=& \left( X_1 \lvert \dots \lvert X_m \right) \\
    A &=& Y H^T(HH^T)^{-1}
\end{eqnarray*}
Esto permite mediante una formula compleja pero eficiente actualizar $A$ rapidamente para remover y agregar \textit{templates}.
O sea, permite ignorar secciones ocultas del objeto hasta que estas vuelven ser visibles.

\subsection{Local learning}
% Local learning

El aprendizaje local, o \textit{local learning}, puede resolver razonablemente el problema del seguimiento de objetos en secuencias de imágenes, lo
que ha sido un tema de investigación en el área del aprendizaje automático \cite{local-learning-machine-learnin} y usado principalmente en la clasificación 
de imágenes, recuperación y reconocimiento de objetos. A diferencia del aprendizaje global, \textit{global learning}, que entrena un modelo global basado en 
todos los datos de entrenamiento, local learning considera varios modelos locales, cada uno extraído de solamente un subconjunto de los datos de entrenamiento.
Este tipo de enfoque enfatiza la idea de que un modelo local puede caracterizar mejor las propiedades intrínsecas y discriminativas de su correspondiente 
subconjunto de datos, que un modelo global para el conjunto completo de datos. De esto se desprende que utilizar múltiples modelos locales puede ofrecer 
mejores resultados cuando los datos están distribuidos de manera complicadao o poco clara.\\
Si bien se puede pensar al seguimiento de objetos como una tarea de clasificación binaria 
que apunta a separar el objeto del resto de la imagen o fondo, en realidad, el principal
problema reside en relacionar las apariciones del objeto entre 2 cuadros, \textit{frames},
consecutivos. Es por esto que la métrica de distancia para determinar el grado de 
relación entre los puntos característicos del objeto adquiere muchísima importancia.
Una simple medida de distancia como la distancia Euclideana puede llevar a algoritmos
de tracking inestables a la hora de diferenciar el objeto del fondo de la imagen. Por
lo tano, es necesario diseñar una medida de distancia eficiente y discriminativa. Esta 
es la idea princial que proponen Li y Lu \cite{local-learning}.\\
La función de distancia que usan es una combinación lineal de distancias elementales, 
como se presenta en \cite{malisiewicz-cvpr08}. Definen a la función de distancia de un 
ejemplar (punto característico) $e$, $D_{e}$ como:

\begin{equation}
    \label{eq:distance-exemplar}
    D_{e}(z) = w_{e} \cdot d_{ez}
\end{equation}

donde $w_{e}$ es el vector de pesos de $e$, y $d_{ez}$ es el vector de distancia 
n-dimensional entre $e$ y $z$, cuya n-ésima componente es la distancia $L_{2}$ 
entre la característica n-ésima de $e$ y $z$.\\
Cada ejemplar está también asociado con un vector binario $B_{e}$, cuyos elementos 
no nulos implican que los ejemplares correspondientes son similares a $e$. La 
longitud de $B_{e}$ es igual al número de ejemplares con el mismo rótulo de $e$.
Asumiendo que el aprendizaje de cada una de las funciones de distancia es 
independiente del resto, se puede aprender $w_{e}$ y $B_{e}$, en un problema 
de aprendizaje formulado de la siguiente manera:

\begin{equation}
    \label{eq:learning-problem}
    f_{1}(w,B) = \sum_{i \in C} B_{i}L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}
\begin{equation}
    {w^{*}, B^{*} = \argmin_{w,b} f_{1} (w,b) }
\end{equation}
\begin{equation}
   w \geq 0, B_{i} \in {0,1}, \sum_{i} B_{i} = M
\end{equation}

El conjunto $C$ es el conjunto de todos los ejemplares con el mismo rótulo que $e$ y $M$ 
es el mínimo número de ejemplares similares a $e$ (predefinido). La función $L$ puede ser
cualquier función de costo o pérdida, \textit{loss function}, positiva.
El vector de pesos $w$
se requiere que sea positivo para asegurar que una mayor distancia elemental (entre 
alguna de las características) no pueda nunca llevar a una menor distancia total, 
lo que implicaría una mayor similaridad.\\

Previo al seguimiento se deben especificar manualmente algunos parámetros iniciales, 
como ser: punto central, ancho, altura y rotación del objeto. En el proceso de 
entrenamiento, se aplica un Análisis de la Componente Principal (PCA, 
\textit{Principal Component Analysis}) de forma incremental en los primeros $F$ cuadros.
Los resultados se seleccionan como muestras de entrenamiento positivas, mientrás que
los peores resultados, se toman como muestras negativas. Se obtienen las características 
RGB y LBP, como se presentan en \cite{tracking-bag-of-features}, de todas las muestras, 
tanto positivas como negativas. Para cada muestra de entrenamiento, se calculan las 
distancias elementales RGB y LBP con respecto a todas las restantes muestras.
Para obtener el vector de pesos óptimo, $w^{*}$, se estimar iterativamente $B$, 
en función de $w$, y $w$ en función de $B$, asegurando que el valor de $f_{1}$ nunca 
crezca, para encontrar un mínimo local. Este proceso iterativo se modelar de la 
siguiente forma:

\begin{equation}
   \label{eq:local-learning-B-k}
   B^{k} = \argmin_{B} \sum_{i \in C} B_{i}L(-w^{k} \cdot d_{i})
\end{equation}
\begin{equation}
    \label{eq:local-learning-w-k}
    w^{k+1} = \argmin_{w} \sum_{i:B_{i}^{k}=1} L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}

Dado un $w^{k}$, que inicialmente podría ser aleatorio, se minimiza la ecuación 
\ref{eq:local-learning-B-k} fijando $B_{i} = 1$ para los $M$ valores más
pequeños de $L(-w \cdot d_{i})$ y $0$ para el resto. Dado $B^{k}$, se puede
obtener fácilmente $w^{k}$, resolviendo la ecuación \ref{eq:local-learning-w-k}. 
El aprendizaje termina cuando $B^{k+1}=B^{k}$.\\

En el proceso de seguimiento, para cada cuadro nuevo, se generan los
candidatos de manera aleatoria, utilizando un filtro de partículas,
\textit{particle filter}, alrededor del resultado del 
seguimiento en el cuadro anterior. Luego, se extraen las características
RGB Y LBP como muestras de testeo. Después de calcular las distancias
elementales entre las muestras de testeo y de entrenamiento, se 
forma una matriz de distancia, $DM: N_{test} \times N_{train}$ a través
de las funciones de distancia entrenadas. Finalmente, se utiliza la 
matriz $DM$ para localizar al objeto como sigue:

\begin{equation}
    T = \argmin_{t} c \sum_{i} D_{i}(t) + (1 - c) \sum_{j} D_{j}(t)
\end{equation}

\begin{equation}
    \forall i \in \{i : i \in S^{+}, D_{i}(t) \leq Thr_{D} \}
\end{equation}
\begin{equation}
    \forall j \in \{j : j \in S^{+}, D_{j}(t) > Thr_{D} \}
\end{equation}

Donde $t$ es un posible candidato y $T$ es el objeto. $S^{+}$ es el 
conjunto de muestras de entrenamiento positivas. La idea consiste en 
que las muestras cuyas distancias sean menor que el umbral $Thr_{D}$
contribuyan más a localizar el objeto, entonces la constante $c$ 
debería tener un valor acorde, $c > 0.5$ (0.7).\\

El algoritmo de seguimiento se complementa con una adición más, que 
intenta atacar el problema de los cambios de poses y las oclusiones.
Para esto es necesario actualizar el modelo que se tiene para 
que efectivamente pueda manejar estas dificultades. 
Haciendo uso del umbral de distancia $Thr_{D}$ para prevenir
malas actualizaciones, se intenta realizar correciones al modelo,
en este caso, las funciones de distancia. Esto es, una distancia
menor a $Thr_{D}$ indica se el candidato pertence a la misma clase,
mientras que una distancia mayor indica lo contrario. Utilizando 
la ecuación \ref{eq:learning-model-update}, se agregan candidatos,
como muestras positivas de entrenamiento y, cada 5 cuadros, 
se utiliza el conjunto actualizado de entrenamiento para 
reentrenar todas las funciones de distancia.

\begin{equation}
    \label{eq:learning-model-update}
    t_{label} = \left\{ 
                \begin{array}{l l}
                    1, & D_{S^{+}}(t) \leq Tht_{D}\\
                    0, & D_{S^{+}}(t) >  Tht_{D}
                \end{array} \right.
\end{equation}

\begin{equation}
    D_{S^{+}}(t) = \dfrac{1}{N_{S^{+}}} \sum_{i \in S^{+}} D_{i}(t)
\end{equation}

En la ecuación \ref{eq:learning-model-update}, $N_{S^{+}}$ es el 
número de muestras positivas de entrenamiento y $D_{S^{+}}(t)$
es el promedio de distancia del candidato $t$ a las muestras
de entrenamiento positivas.

\subsection{Graph based}
% IFTrace

El algoritmo conocido como \textit{IFTrace} tiene como objetivo demarcar un objeto en una secuencia de video. Este algoritmo hace mínimas
suposiciones sobre el objeto a seguir: básicamente que consista de algunas regiones conexas, que tenga un borde bien definido y que sus propiedades
intrínsecas pueden variar con el tiempo.\\
Los objetos a seguir son incialmente marcados de forma interactiva por el usuario en el primer cuadro, y luego se seleccionan automáticamente
varios marcadores en el interior y los alrededores del objeto. Estos marcadores se localizan en el siguiente cuadro utilizando en forma
conjunta el algoritmo de
seguimiento de características KLT \cite{KLT} y extrapolación de movimiento. Los bordes del objeto son entonces identificados a partir de estos marcadores por la IFT, 
\textit{Image Foresting Transform}\cite{IFT}. Otra característica vital del algoritmo es el operador de detección de borde que se adapta gradualmente a cambios en el 
color y la textura del objeto. \\

Al igual que otros métodos de segmentación de objetos basados en grafos, IFT trata a la imagen como un grafo, en el cual los pixeles son los nodos, y
estos están conectados mediantes aristas si son adyacentes y tiene un peso o costo. Este costo debe ser una medida de la probabilidad de que 
los puntos estén separados por el borde del objeto trackeado. En problemas sencillos puede ser tan simple como el valor absoluto de la diferencia de color 
entre los pixeles. IFTrace combina el gradiente del color con el gradiente de una función de clasificación de pixeles difusos, algo así como la similaridad entre el pixel 
y el set de pixeles del objeto segmentado en el frame anterior. \\

La IFT encuentra caminos de costo mínimo desde los marcadores, tanto internos como externos, a cada pixel de la imagen. Entonces, los pixeles son particionados en un conjunto
disjunto de árboles de camino óptimo, con cada árbol con uno de los marcadores como raíz. La proyección del objeto es entonces tomada como la union de los árboles cuyas raices 
son marcadores internos.\\

 \begin{figure}[H]
%         \includegraphics[width=\linewidth]{images/lena#1.png}
        \caption{FIGURA con ALGORITHM 1}
        \label{fig:IFTrace-algorithm1}
\end{figure}


La figura \ref{fig:IFTrace-algorithm1} muestra el algoritmo de IFTrace desde el más alto nivel.
IFTrace toma como input un video, modelado como un array 3D de pixeles, siendo las dimensiones el alto y ancho de la imagen, y número de cuadro de la secuencia de video, y una 
máscara binaria, correspondiente al objeto marcado en el primer cuadro, y devuelve un array de máscaras binarias, con las proyecciones del objeto para cada cuadro del video.
Para cada cuadro de la secuencia, el algoritmo elije dos conjuntos de puntos o pixeles: los que pertenecen a la máscara del objeto, y los que pertencen a sus alrededores. Luego se 
procede 
a localizarlos en el siguiente cuadro (\textit{trackMarkers}). Si el conjunto de pixeles que representan al objeto no resulta vacío para este nuevo cuadro, entonces el seguimiento
fue exitoso, y se procede a utilizar IFT para, a partir de los dos conjuntos de pixeles, el clasificador de color del cuadro anterior y el cuadro actual, obtener la máscara del 
objeto para el cuadro actual (\textit{IFTSegment}). Como paso final, se obtiene el clasificador de color del cuadro actual a partir de la máscara del objeto y el cuadro actual.
Por otro lado, si el seguimiento del objeto falla para el nuevo cuadro, es decir si el conjunto de pixeles resultantes luego de aplicar \textit{trackMarkers} resulta vacío, 
entonces se mantiene el mismo clasificador de color del cuadro anterior y se procede
a intentar recuperar el objeto en el cuadro actual (\textit{recoverObj}). Si la recuperación
es exitosa, se obtiene un máscara del objeto y un clasificador de color para el cuadro actual,
sino, todos los conjuntos se dejan vacíos y el clasificador se mantiene inalterado.\

Recuperación del objeto\\
 \begin{figure}[H]
%         \includegraphics[width=\linewidth]{images/lena#1.png}
        \caption{FIGURA con ALGORITHM 2}
        \label{fig:IFTrace-algorithm2}
\end{figure}

Si en algún paso del algoritmo IFTrace, se falla en el seguimiento del objeto, se 
procede a utilizar a la heurística \textit{recoverObj}, que intenta localizar una
región conexa cuya forma y colores sea similar a la del objeto en alguno de los 
cuadros anteriores.\\

La heurística se aplica utilizando un cuadro de referencia, e iterando hacia atrás
hasta encontrar un cuadro en el que se pueda recuperar el objeto, evitando 
utilizar cuadros previos en los que no se pudo recuperar el objeto anteriormente.
Una vez ubicado el cuadro de referencia en el cual el tracking fue exitoso, 
se construye una ``máscara candidata'' $M$ que indica las posibles ubicaciones
del objeto en el cuadro actual $t$ (\textit{CandidateMask}). En este paso se 
utiliza el clasificador de color del cuadro de referencia $k$. La máscara 
etiqueta los pixeles del cuadro como ``posiblemente objeto''(1) o 
``probablemente fondo''(0). Esta máscara $M$ estará compuesta de cero
o más regiones conexas. Si el objeto está visible en el cuadro actual, 
su proyección debería coincidir con alguna de estas regiones. Entonces 
se procede a analizar cada una de estas regiones, para las cuales se obtienen
los dos conjuntos de marcadores, utilizando la misma técnica que en el
en algoritmo 1 en la figura \ref{fig:IFTrace-algorithm1}. Luego se utiliza 
nuevamente el algoritmo IFT para conseguir una proyección $K$ de esa región que 
se está analizando, para luego compararla con la máscara del objeto en el cuadro
$k$ utilizado como referencia. En caso de ser similar, se construye el clasificador
de color $C'$ y se retorna junto a la proyección $K'$ como máscara representativa 
del objeto para el actual cuadro. \\
Cabe destacar que, por simplicidad, para la comparación de formas se utilizan
las Invariantes de Momento de Maitra \cite{MaitraMomentInvariants}, y las formas se consideran similares
si la distancia Euclideana entre sus vectores de invariantes es menor a 2. 
Sin embargo se podría utilizar otros descriptores de formas.\\
Si ninguna de las regiones resulta similar a la máscara del objeto, 
\textit{recoverObj} intenta el mismo procedimiento utilizando como cuadro de 
referencia el cuadro anterior. Luego de un número especificado de intentos, o
de agotar todos los cuadros, la heurística termina. En este caso, se retorna
una máscara vacía y un clasificador nulo, señalando que el objeto se perdió en
el cuadro actual. \textit{IFTrace} intentará entonces recuperar en el siguiente 
cuadro.

Selección de marcadores
El procedimiento \textit{selectMarkers} es el encargado de elegir dos conjuntos 
de marcadores, los que están dentro de la máscara del objeto, y los que están a
su alrededor.\\

Los marcadores internos se eligen aplicando una erosión morfológica 
(\textit{morphological erosion}) a la máscara del objeto, con radio $\delta_{o}$, y 
luego seleccionando los pixeles de la región resultante que tengan mayor probabilidad
de ser trackeados por el algoritmo KLT. Específicamente, se construye la matriz:

 \begin{figure}[H]
%         \includegraphics[width=\linewidth]{images/lena#1.png}
        \caption{FIGURA Matriz H(p)}
        \label{fig:IFTrace-matrix-H}
\end{figure}

donde $L[p]$ es la luminancia del pixel $p$, y las sumatorias incluyen a todos los
pixeles $q$ en una ventana de $9x9$ centrada en $p$.\\
Se define el grado de ``igualdad'' $\lambda[p]$ como el valor mínimo de $H[p]$. 
Solo los pixeles con $\lambda > 1$ son escogidos para utilizarlos en la 
propagación KLT. Esto coincide con los autores Tomasi y Karade \cite{Tomasi91detectionand}
quienes afirman que los pixeles con mayor $\lambda$ tienen más posibilidades
de ser localizados por el algoritmo KLT.\\
Los marcadores externos son escogidos aplicando una dilatación morfológica, con 
cierto radio $\delta_{x}$, y tomando los pixeles a lo largo del borde del resultado.

Seguimiento de Marcadores, \textit{Marker Tracking}
El procedimiento \textit{trackMarkers} se utiliza para localizar los marcadores 
internos en el cuadro actual, que se corresponden con los puntos internos del objeto
en el cuadro anterior. Utiliza el algoritmo de seguimiento KLT. descrito por Tomasi y 
Karade \cite{Tomasi91detectionand}.\\
El algoritmo KLT recibe un punto $p$ en un cuadro $I^{t-1}$, una posición estimada 
$q_{0}$ en el próximo cuadro $I^{t}$, y busca un punto $q$ tal que los vecinos
de $q$ en $I^{t}$ sean similares a los de $p$ en $I^{t-1}$. Este algoritmo tiene
varios parámetros de configuración que alteran su comportamiento: $\ell$, la cantidad
escalas consideradas; $\kappa$, el factor de reducción entre las sucesivas escalas; y 
$\omega$, el ancho de la ventana usada para comparar vecinos en cada escala. 
La implementación de IFTrace está configurada para usar $\ell=2$,$\kappa=4$ y 
$\omega=9$, como en la implementación de KLT de Birchfield \cite{Birchfield-KLT-implementation}.\\

Los marcadores exteriores no son trackeados con KLT, ya que no tiene sentido debido
a que la mayoría se perdería por oclusión con el objeto o trackearía el fondo, en 
vez del objeto. En cambio, lo que se hace es trasladarlos de acuerdo a los 
desplazamientos medios de los marcadores internos más cercanos. Esto tiende
a mantener estos marcadores fuera del objeto, pero cerca de su borde, aún cuando
hay rápidos cambios de tamaño o de forma (por ejemplo, rotaciones o movimiento de extremidades).\\


Segmentación de objetos a través de la IFT\\
La IFT interpreta a la imagen $I$ como un grafo $G$, cuyos nodos son los pixeles y cuyas
aristas relacionand pixeles adyacentes. IFT toma como parámetros un conjunto de 
pixeles marcadores $S$, una función de costo de arista $w$, y una función de 
conectividad $f$ que asigna un costo de camino $f(\pi)$ a todo camino $\pi$ in $G$,
dependiendo del costo de sus aristas.\\
Para pixel $p$, IFT encuentra un camino directo óptimo (de costo mínimo), que lo 
conecta con su raíz $R(p)$ en el conjunto $S$ de pixeles marcadores. Si la función 
$f$ cumple ciertas propiedades básicas, estos caminos forman un bosque de caminos 
óptimos, \textit{optimum-path forest}. Cada árbol en este bosque de caminos óptimos
tiene como raíz a algun marcador $r$, y agrupa a todos los pixeles de la imagen que 
están mejor conectados a $r$ que a cualquier otro marcador. IFT también le asigna a 
cada pixel $p$ un costo $V(p) = \pi(p)$, y un marcador raíz $R(p)$, el marcador 
que se encuentra en la raíz del árbol al cual pertenece.\\

IFT\\
IFT es una herramienta extramadamente general, de la cual se pueden obtener diferentes
operadores de imágenes, variando sus parámetros de entrada. IFTrace depende de la IFT
para segmentar los objetos a trackear. Usa la función de conectividad $f_{max}$, que
asigna a un camino $\pi$ el máximo costo $w(a)$ para todas las aritas $a$ en $\pi$.
Los pixeles marcadores utilizados son tanto los marcadores interiores, obtenidos
por el algoritmo KLT, como los exteriores que se ubican alrededor del objeto.\\
La segmentación obtenida al usar $f_{max}$ tiene una importante propiedad 
\textit{minimax}: maximiza el costo mínimo de todas las aristas en la frontera de la 
segmentación. Esto significa que la segmentación IFT/$f_{max}$ es esencialmente
la misma que la segmentación \textit{watershed} \cite{watershed-segmentation}. Esto 
hace que sea particularmente apropiada para casos en los que el objeto esté 
mejor caracterizado por su conectividad que por su forma o tamaño. Es por esto que 
se elige una función de costo de arista $w(p,q)$ que se base en la probabilidad de 
que $p$ y $q$ estén en diferentes lados del borde del objeto.\\

Algoritmo IFT\\
Para algunas funciones de conectividad, como $f_{max}$, el bosque de caminos
óptimos se puede computar eficientemente mediante una variante del famoso 
algoritmo de Dijkstra \cite{watershed-segmentation}. Por cuestiones de
eficiencia, el algoritmo retorna un mapa de raices $R$, que almacena, para 
cada nodo $p$, su raíz $R(p)$.\\

 \begin{figure}[H]
%         \includegraphics[width=\linewidth]{images/lena#1.png}
        \caption{FIGURA ALGORITMO IFT}
        \label{fig:IFTrace-IFT-algorithm}
\end{figure}

Inicialmente se inicializan los mapas para caminos triviales. Se agregan 
los nodos que representan marcadores a la cola $Q$. El ciclo \textit{while}
principal computa un camino óptimo desde las raíces a cada nodo $p$. En 
cada iteración, un camino de valor $V(p)$ mínimo se encuentra cuando
removemos el último pixel $p$ de la cola. Luego se evalua si el camino que
alcanza el pixel adyacente $q$ a través de $p$ es más barato que el actual 
camino que termina en $q$ y se actualizan $Q$, $V(q)$, $R(q)$ y $P(q)$ 
acordemente.\\
Este algoritmo se puede modificar para recomputar el bosque de camino óptimo 
de forma incremental, a medida que se van agregan o quitando marcadores, 
generalmente en tiempo sub-lineal.\\

Comparación con otros algoritmos de Graph-Cut\\

Boykov and Funka-Lea [5,12] han propuesto otra alternativa para la segmentación
de imágenes basada en grafos, conocida como \textit{Graph-Cut}, que explota 
la conexión que existe entre cortes de capacidad mínimos y flujos de volumen
máximo. En este enfoque, el grafo de pixeles se modela como una red de flujo,
donde el objeto es la fuente (\textit{source}) y el fondo el sumidero
(\textit{sink}). Se puede provar que el máximo flujo total de todas las fuentes
hacia todos los sumideros es igual a mínima capacidad total de todo corte 
(conjunto de aristas) que separa fuentes de sumideros. Este flujo máximo y su 
corte mínimo asociado se puede encontrar con el clásico algoritmo 
Ford Fulkerson \cite{Cormen:2009:IAT:1614191}.\\
En comparación con la IFT, \textit{Graph-Cut} tiene 2 grandes desventajas: es 
considerablemente más caro computacionalmente (IFT es $O(n)$ mientras que
el mejor algoritmo \textit{Graph-Cut} es $O(n^{2.5})$), y además tiende a 
minimizar el número de aristas en el corte, en vez de sus capacidades. Esto 
último quiere decir que muestra una preferencia a segmentar basada en la 
longitud del borde, en vez de la importancia de la conexión entre el objeto y 
el fondo.(REF 11)\\
Se puede introducir una corrección al algoritmo de \textit{Graph-Cut} para 
remediar este segunda problema, pero lo único que se obtiene es el mismos 
resultado de la IFT, con un costo computacional mucho mayor. (REF 11)

Costo de arista de IFT\\

Como ya se explicó anteriormente, IFT opera con una función de costo de arista
$w$, la cual resulta crítica para la segmentación. Idealmente, el costo 
para aristas que cruzan el borde del objeto debería ser alto, y bajo para todo
el resto. En otras palabras, la función de costo debería ser un detector
de bordes del objeto.\\
Un ejemplo podría ser la distancia Euclideana entre los colores RGB de los pixeles 
en ambos extremos de una arista. Desafortunadamente, este detector resulta demasiado 
simplista para casos prácticos, en los que un objeto puede tener diferentes colores y 
texturas. Por lo tanto, se requieren detectores de bordes más sofisticados.\\

En la implementación de \textit{IFTrace}, se utiliza un detector de bordes basado en
una combinación lineal

\begin{equation}
   \label{eq:IFTrace-edge-detector}
   w(p,q) = \gamma w_{f}(p,q) + (1 - \gamma)w_{0}(p,q) = \gamma |\nabla I| + (1 - \gamma)|\nabla M|
\end{equation}

donde $\gamma$ es un parámetro seteable por el usuario, $\nabla I$ es el gradiente
del color de la imagen y $M$ es un mapa de clasificación de color.\\

El primer componente $w_{f})(p,q)$ es la distancia Euclideana entre los colores de 
los extremos de la arista, como se menciona anteriormente pero con una particularidad:
se mide en el espacio de colores $L$ $a$ $b$, en vez del tradicional RGB. La 
justificación para esto es que las distancias entre colores se aprecian más de 
esta forma.\\

El segundo componente $w_{o}(p,q)$, es el gradiente del mapa de clasificación
de colores $M$, una imagen en escala de grises donde cada pixel $M[p]$ es
la probabilidad de que un pixel con color $I[p]$ pertenezca a la proyección
del objeto. Los colores que ocurran solo dentro del objeto deberían estar
asociados al valor 1, los que solo ocurran en el fondo deberían estar 
asociados al 0, y los que puedan ocurrir en ambos, deberían mapearse a 
valores intermedios. El propósito de incluir este término es restarle 
importancia a los bordes entre colores que son internos del objeto, o 
totalmente ajenos al objeto, y enfatizar los bordes que efectivamente 
delimitan el objeto del fondo de la imagen.\\

El mapa de clasificación de colores $M$ se obtiene de la imagen $I$ por medio de un
clasificador de color difuso $C$, una función no lineal $C : \mathbb{V} \to [0,1]$.
En \textit{IFTrace}, la función $C$ se implementa como una variante del clasificador
del vecino más cercano, \textit{nearest neighbor} (NN). Para evaluar $C(v)$ para 
cierto color $v$, se debe buscar 2 colores representantes $u_{0} \in \mathbb{U_{0}}$ 
y $u_{x} \in \mathbb{U_{x}}$ que son los más cercanos a $v$, dentro de los colores de
de los conjuntos de marcadores internos, $\mathbb{U_{0}}$, y externos, $\mathbb{U_{x}}$.
La probabilidad de que un pixel de color $v$ sea parte del objeto es entonces estimada
por la fórmula

\begin{equation}
   \label{eq:IFTrace-color-classifier}
   C(v) = \frac{|v - u_{0}|}{|v - u_{0}| + |v - u_{x}|}
\end{equation}

En teoría, se podría usar todos los pixeles para construir los conjuntos 
$\mathbb{U_{0}}$ y $\mathbb{U_{x}}$. Pero en la práctica, se deben usar muestras 
de menor tamaño por razones eficiencia, de otra forma, el costo de encontrar los
representantes $u_{0},u_{x}$ aumenta demasiado. De hecho, la construcción del mapa
$M$ resulta ser el paso más caro computacionalmente de \textit{IFTrace}, más
aún que el seguimiento de marcadores y que la segmentación de la IFT.\\
Es por esto que el procedimiento para construir el clasificador, 
\textit{buildClassifier}, comienza seleccionando dos conjuntos de pixeles 
$R_{0},R_{x}$, respectivamente los que están dentro y fuera de la actual máscara
del objeto. Pero si alguno de estos conjuntos tiene mñas de 200 elementos,
entonces se realiza un muestreo aleatorio para reducirlos a ese tamaño.

\subsection{Contornos Activo}

% TODO: Write me

\section{Analisis de deportes con 6 camaras}
\label{sec:6-camaras}

% Tanos

\section{Analisis de deportes con 8 camaras}
\label{sec:8-camaras}

\citeauthor*{xu-8cams} proponen un sistema que consta de 8 cámaras conectadas a sistemas que 
analizan la información y a través de una capa de red envían la información a un supervisor,
encargado del mantenimiento de la posición de los jugadores. El sistema supervisor no tiene 
acceso a los datos crudos de la imágen obtenida.

Cada cámara realiza un preprocesamiento de la imágen para estimar la posición de la cámara y
detectar áreas de interés (candidatos a ser los jugadores en pantalla). Para la eliminación
del fondo, se utilizan dos máscaras, una geométrica, que se aproxima a la geometría de la
cancha y una que extrae información acerca de los píxeles y genera un histograma para
detectar el color verde del pasto de la cancha. Para la primera máscara, se pasa la imágen de
RGB a HSI y se analiza el histograma de \textit{hue} para los mayores valores de intensidad.
Luego, los píxeles que serán considerados son aquellos que no pertenezcan a un rango de \textit{hue}
entre un mínimo y un máximo, correspondientes a los valores que hagan que el máximo valor
del histograma caiga al 10\% de su valor original.  Luego, la máscara que elimina valores
de acuerdo a su color queda definida por:

\[
  M_c = ({(u, v) | H(u, v) \in [H_l, H_h]} \oplus B ) \ominus B
\]

Donde $B$ es un elemento estructurador cuadrado y $\oplus$ y $\ominus$ son los operadores
morfológicos de erosión y dilatación, aplicados para separar a los jugadores y eliminar las
líneas de campo blancas. La máscara geométrica comprende los siguientes puntos:

\[
  M_g = { (u, v) | E(u, v)  \in P }
\]

Donde P es el rango de coordenadas en el mundo real correspondiente a la cancha y $E(u, v)$ es 
la correspondencia del punto $(u, v)$ en el mundo real, de acuerdo a una corrección utilizando
ángulos de Euler. Por último la máscara que determina aquellos pixeles que corresponden al
pasto de la cancha son los que pertenecen a la intersección de ambas máscaras:

\[
  M = M_c \cap M_g
\]

Las \textit{bounding boxes} de los objetos candidatos a ser jugadores son representadas por
la posición en el plano de la imágen $\mathbf{x}_l$ y su error en la medición $\mathbf{z}_l$ en
un filtro de Kalman:

\[
\mathbf{x}_l = [r_c \; c_c \;  \mathbf{\dot r}_c  \; \mathbf{\dot c}_c \;  \Delta r_1  \; \Delta c_1 \;  \Delta r_2 \;  \Delta c_2]^T
\]

\[
\mathbf{z}_l = [r_c \;  c_c  \; r_1  \; c_1  \; r_2  \; c_2]^T
\]

Donde $r_1 < r_2$ y $c_1 < c_2$ son los límites de la \textit{bounding box} y $r_c$ y $c_c$ son los
centroides de la \textit{bounding box}. Estos valores son actualizados cuadro por cuadro,
asumiendo que la variación en alto y ancho es baja. Se utilizan ángulos de Euler para
traducir estos valores a la posición esperada dentro del plano de la cancha. La varianza es estimada
utilizando el jacobiano de la matriz de Euler. Por último, se analiza la categoría de los
jugadores de acuerdo al histograma de colores, clasificando de acuerdo a los cinco posibles uniformes
(uno para cada equipo, uno para cada arquero, y los árbitros).

El módulo supervisor recibe de cada computadora los datos preprocesados y ninguna información
acerca de las imágenes. Se unifican los valores obtenidos de todos los módulos y se los asocia
utilizando una matriz que es actualizada de acuerdo a la distancia de Mahalanobis. Si esta
distancia queda por debajo de un determinado umbral, se empieza a considerar que las mediciones
de dos cámaras distintas para dos \textit{bounding boxes} pasan a ser el mismo jugador.

\section{Analisis de deportes con multiples camaras}
\label{sec:var-camaras}

% SIFT Base blablablabla
\subsection{Camera-based Observation of Football Games for Analyzing Multi-agent Activities}

\citeauthor*{beetz-05, beetz-06} analizaron, desde el punto de vista de la inteligencia artificial,
el problema de detectar el comportamiento de los jugadores dentro de la cancha. Para eso, propusieron
un sistema con dos módulos, uno que extrae características e información de videos provenientes de
un numero indeterminado de cámaras, y un módulo de análisis y seguimiento del comportamiento de cada
objeto (un sector de la imágen candidato a ser la pelota o una persona en el campo de juego, 
llamado \textit{blob} por los autores).

Respecto al módulo visual, encontraron una gran dificultad en detectar la posición de jugadores más alejados
de la cámara, dado que el material con el que trabajaron en general eran cámaras situadas a no más de
18 metros de altura. Esto hacía que la resolución en el lateral opuesto de la cancha sea de 1,5 metros por píxel,
insuficiente para hacer un análisis real de la información obtenida.

Su trabajo utiliza fuertemente la detección de líneas en la cancha, tanto las líneas blancas que demarcan sectores
importantes del campo de juego, como de distintos tonos de verde en franjas que es frecuentemente el caso del césped de
estadios de Europa. Esta característica no se vé en las canchas de fútbol en la mayoría de los países de América Latina.

Para mantener información acerca del movimiento sobre el eje de la cámara (denominado \textit{panning}), se utilizó
un algoritmo de aprendizaje para detectar características en los carteles publicitarios usualmente presentes en los
laterales de la cancha. Esto ayuda a la robustez del algoritmo, pero en ciertos casos no es suficiente, como sucede
cuando el camarógrafo mueve la cámara rápidamente para no perder de vista la pelota en el caso de un pase largo.
El máximo tiempo que reportan para el seguimiento correcto de la orientación y posición de la cámara es de 2,5 minutos.

El análisis del video se compone de las siguientes etapas:

\begin{itemize}
  \item \textbf{Segmentación por color}: Se diferencia el verde de la cancha, los jugadores, la publicidad de fondo,
  y las líneas blancas de la cancha mediante el color de los mismos. Debido a diferencias de
  iluminación, se actualizan los parámetros para la detección de valores que corresponden al pasto verde de acuerdo
  a un algoritmo de aprendizaje que es sensible al ángulo estimado de la cámara y al tiempo.
  \item \textbf{Estimación de la posición de la cámara}: Se tiene un modelo de los bordes rectos que debieran detectarse
  en la cámara, y sus posiciones en tres dimensiones. A partir de esto, se obtienen datos acerca de la perspectiva.
  Para fortalecer la detección, se
  corrigen las posiciones utilizando un algoritmo de aprendizaje que toma como entrada las publicidades que se ven en 
  el extremo opuesto de la cancha.
  \item \textbf{Detección de \textit{blobs}}: Otros objetos que no sean verdes o blancos (pasto o líneas de la cancha)
  son candidatos a ser jugadores o el árbitro. Estos son segmentados y analizados en busca de ciertas características:
  se espera que en general sean más altos que anchos, con segmentos definidos: pelo, camisa, piernas, que son
  aprendidos y actualizados a lo largo del análisis.
\end{itemize}

Luego del análisis de características del video, el procesamiento y seguimiento de los jugadores es realizado utilizando
una extensión del algoritmo \textbf{Multiple Hypothesis Tracking(MHT)} \cite{MHT-1, MHT-2} mejorado por \citeauthor*{Schmitt-1, Schmitt-2}
Este algoritmo utiliza un modelo de cámara y movimiento probabilístico para estimar la posición de los jugadores
y actualizarlas en cada observación. Se utilizan muchas hipótesis propias de las características de un partido
de fútbol para mejorar esta estimación: 
\begin{itemize}
  \item \textbf{Trackeo de personas}: No se dá el caso de que un jugador desaparezca de la cancha de un \textit{frame}
  a otro. Aparecen gradualmente desde el borde del campo de visión.
  \item \textbf{Oclusiones entre jugadores}: No se descarta la información sobre la estimación de un jugador cuando 
  éste pasa a estar ocluído por otro jugador.
  \item \textbf{Jugadores sobre un plano}: Se asume que la cancha es un plano tridimencional y que los jugadores
  están posicionados sobre este plano. Esto además permite relacionar el tamaño de los \textit{blobs} con la cercanía
  del jugador a la cámara.
\end{itemize}

Por último, este análisis genera información de alto nivel semántico en forma de \textit{movimientos}
y \textit{episodios}. Para modelar los movimientos de la pelota, se asumió que la pelota se mueve linealmente por partes.
Un episodio es definido como la secuencia de \textit{movimientos} de la pelota desde que un jugador toma control
de ella hasta que lo pierde. Los movimientos exitosos que un jugador ejecuta en este modelo son pases, tiros al arco,
o cambios bruscos de dirección (llamado \textit{dribbling} por los autores).

\section{Analisis de deportes con video televizado}
\label{sec:tv-video}

\subsection{\citetitle{LIU20061146}}

En \cite{LIU20061146} se plantea una tecnica para obtener las posiciones de los jugadores y la pelota utilizando la transmision televizada de un partido de futbol.
El algoritmo se puede dividir en los siguientes grandes rasgos:
\begin{itemize}
\item Estimacion de la relacion entre puntos en la imagen y coordenadas en la cancha
\item Estimacion de la posicion de la camara en las coordenadas del mundo
\item Deteccion y tracking de la pelota
\item Deteccion de la cancha
\item Deteccion de los jugadores
\end{itemize}

Para estimar la relacion entre los puntos en la imagen y las coordenadas en la cancha se calcula una homografia.
Siendo $M = (x, y, 1)$ un punto en el plano de la cancha en coordenadas homogeneas y $m = (u, v, 1)$ la posicion del punto en la imagen, se puede convertir $ m = H M $.

Como la perspectiva de la camara cambia cuadro a cuadro, esta debe ser calculada en cada cuadro nuevamente.
Si en la imagen actual se encuentran 4 puntos conocidos (Esquinas de la cancha o de las areas), la homografia puede ser calculada directamente.
De no ser asi, se estima considerando que la homografia del cuadro actual $H_t$ se puede relacionar con $H_{t-1}$ mediante un \textit{Global Motion Parameter} $P$.
Este parametro $P_{t-1,t}$ se calcula tomando una serie de puntos en la imagen y relacionando su posicion entre el cuadro $t-1$ y $t$.
Luego $ H_t = H_{t-1} P_{t-1,t}$.

Para obtener la posicion de la camara se descompone la homografia en 2 matrices:
\begin{equation}
H = K \begin{bmatrix} r_1 & r_2 & t \end{bmatrix}
K = \begin{pmatrix} 
    \alpha & \gamma & u_0 \\
    0 & \beta & v_0 \\
    0 & 0 & 1
    \end{pmatrix}
\end{equation}

Donde $\alpha$, $\beta$ representan la amplitud focal de la camara, $\gamma$ representa el \textit{skew} y $(u_0, v_0)$ es la coordenada del punto principal.
Se asume que la amplitud focal se mantiene constante, $\gamma = 0$ y el punto principal es el centro de la imagen.
$r_1$, $r_2$ son parte de una rotacion $R = (r_1, r_2, r_1 \times r_2)$, y $t$ son las coordenadas del origen de la cancha en coordenadas de la imagen.
Conocidas $H$ y $K$ se puede calcular la posicion de la camara como $R^{-1} t$.
Para el calculo de $K$ se necesita $\alpha$ y $\beta$ que se calcula usando $P$ de la siguiente manera:

\begin{equation}
\begin{bmatrix}
    p_{1 1} p_{2 1} & p_{1 2} p_{2 2} \\
    p_{1 1} p_{3 1} & p_{1 2} p_{3 2} \\
    p_{1 1} p_{3 1} & p_{2 2} p_{3 2} 
\end{bmatrix} 
\begin{bmatrix}
    \alpha^2 \\
    \beta^2
\end{bmatrix}
 =
\begin{bmatrix}
    - p_{1 3} p_{2 3} \\
    - p_{1 3} p_{3 3} \\
    - p_{2 3} p_{3 3} \\
\end{bmatrix}
\end{equation}

Se usa el metodo \textit{KLT} \cite{KLT} para encontrar los puntos de referencia a seguir para el calculo de $P$.

\subsubsection*{Seguimiento de la pelota}

El algoritmo planteado para seguimiento de la pelota tiene 2 etapas.
La primer etapa es de deteccion utilizando un algoritmo basado en \textit{Viterbi}.
La segunda etapa es de seguimiento utilizando un \textit{Kalman Filter}.

Para deteccion se crea una imagen binaria, segmentando segun la caracteristica blanca de la pelota.
Una vez segmentada, se eliminan los candidatos teniendo en cuenta las distintas caracteristicas morfologicas de la pelota. 
Esta operacion se realiza en $T$ cuadros distintos, a partir de esto se construye un grafo pesado.
Los nodos de este grafo representan candidatos, con un peso segun que tan parecidos son a una pelota ideal.
Y los vertices se colocan si estan a una cierta proximidad y pesados segun que tan cerca y parecidos sean los nodos.
Sobre este grafo se hace una busqueda de camino optimo, y de este la posicion de la pelota en el ultimo cuadro.

Una vez detectada la pelota, se utiliza tracking hasta que no se confia en el resultado del algoritmo de tracking.
En esa instancia se vuelve a detectar la pelota con el algoritmo dicho anteriormente.

\subsubsection*{Deteccion de la cancha}

Para detectar la cancha y aislar el resto de los objetos, se computa un histograma de colores de la imagen.
Los autores consideran que el color de la cancha representa el mayor pico en el histograma.
Por lo tanto, buscan este pico en el histograma y toman todos los colores adyacentes en el histograma que esten dentro de un rango de ocurrencia relativo al pico principal.

\subsubsection*{Deteccion de jugadores}

Una vez que se determino el rango de colores de la cancha, se construye una imagen binaria separando la cancha de todo otro objeto.
Construida esta imagen, se aplica la misma tecnica que se usa para seguir la pelota, adaptada a la morfologia de los jugadores.
Como se conoce la posicion en la imagen de los jugadores, y la homografia $H_t$ se puede calcular la posicion real de los jugadores en ese cuadro facilmente.



\section*{Referencias}
\printbibliography

\end{document}
