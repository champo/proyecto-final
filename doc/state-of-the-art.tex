\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[spanish]{babel}
\usepackage[pdftex,usenames,dvipsnames]{color}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage[small,bf]{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{titlesec}
\usepackage[backend=bibtex]{biblatex}
\usepackage{titling}

\addbibresource{references}
\titleformat{\section}{\small\center\bfseries}{\thesection.}{0.5em}{\normalsize\uppercase}
\titleformat{\subsection}{\small\center\bfseries}{}{0.5em}{\small\uppercase}

\def\customabstract{\vspace{.5em}
    {\small\center{\textbf{RESUMEN}} \\[0.5em] \relax%
    }}
\def\endkeywords{\par}

\def\keywords{\vspace{.5em}
    {\textit{Palabras clave: } 
    }}
\def\endkeywords{\par}

% TITLE Configuration
\setlength{\droptitle}{-30pt}
\pretitle{\begin{center}\Huge\begin{rmfamily}}
\posttitle{\par\end{rmfamily}\end{center}\vskip 0.5em}
\preauthor{\begin{center}
        \large \lineskip 0.5em%
\begin{tabular}[t]{c}}
\postauthor{\end{tabular}\normalsize 
    \\[1em] Estudiantes del Instituto Tecnológico de Buenos Aires
\par\end{center}}
\predate{\begin{center}\small}
\postdate{\par\end{center}}

% Headers
\addtolength{\voffset}{-40pt}
\addtolength{\textheight}{80pt}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\lhead{\small No publicado}
\rhead{\small \thepage}
\cfoot{\small Copyright \copyright 2013 ITBA}

% Metadata
\title{}
\date{20 de Septiembre de 2013}
\author{Civile, Juan Pablo \and Crespo, Álvaro \and Ordano, Esteban }

\begin{document}

\pagestyle{fancy}
\maketitle
\thispagestyle{fancy}

\begin{customabstract}
\textbf{
}
\end{customabstract}

\begin{keywords}
\end{keywords}

\newpage

\part*{Estado del Arte}

% Describir la organizacion de esta seccion

\section{Una camara}

Conocemos 3 familias de algoritmos de tracking en video utilizando una sola camara.
Estas son \textit{Linear Predictors}, \textit{Local learning} y \textit{Graph based}.
Pasamos a describir las tecnicas usadas por estos.

\subsection{Linear predictors}

\textit{Linear Predictor} se refiere a crear una relacion lineal \[ Ax = b \] donde $A$ es un predictor, $x$ un valor medido y $b$ otro segundo valor relacionado a $x$ de alguna manera.
En \cite{alp, original-linear-predictors} los autores utilizan predictores que relacionan muestras tomadas de la imagen con el cambio de posicion del objeto.
Para obtener la relacion $A$ se utiliza un paso inicial de entrenamiento.
Se parte de una posicion conocida y se hacen multiples mutaciones obteniendo $N$ cambios de posiciones $b_i$ y sus correspondientes muestras $x_i$.
Luego se define $X = (x_1, \dots, x_N)$ y $B = (b_1, \dots, b_N)$ y se resuelve $AX = B$.

Una vez calculada $A$, en cada cuadro se toman muestras de la imagen usando la ultima posicion conocida del objeto.
Usando estas muestras se calcula el cambio de posicion del objeto mediante $Ax$.
Para mejorar la efectividad de los algoritmos, se calculan varios predictores y se disponen en capas.
Cada capa se construye para buscar cambios de posicion cada vez mas pequeños.
Es decir, la primer capa busca cambios bruscos y la ultima pequeños cambios.

\citeauthor*{alp} introducen varias tecnicas para hacer mas robusto el algoritmo.
Primero calculan la relacion $A$ de forma tal que puede ser facilmente actualizada para soportar cambios en el objeto.
Esto permite detectar oclusiones parciales y cambiar el predictor para que no busque las partes ocultas del objeto.
Una vez que las partes ocultas del objeto entran en el campo visual de vuelta, se vuelve a agregar las partes del predictor que se quitaron previamente.
Esta tecnica ademas permite reentrenar la relacion $A$ con poco costo computacional.
Luego, para soportar cambios de iluminacion en la imagen siempre ajustan las muestras tomadas a una distribucion normal.


% original linear predictors
% ALP

\subsection{Local learning}
% Local learning

\subsection{Graph based}
% IFTrace

\section{6 camaras}

% Tanos

\section{8 camaras}

\section{Multiples camaras}

% SIFT Base blablablabla
\subsection{Camera-based Observation of Football Games for Analyzing Multi-agent Activities}

\citeauthor*{beetz-05, beetz-06} analizaron, desde el punto de vista de la inteligencia artificial,
el problema de detectar el comportamiento de los jugadores dentro de la cancha. Para eso, propusieron
un sistema con dos módulos, uno que extrae características e información de videos provenientes de
un numero indeterminado de cámaras, y un módulo de análisis y seguimiento del comportamiento de cada
objeto (un sector de la imágen candidato a ser la pelota o una persona en el campo de juego, 
llamado \textit{blob} por los autores).

Respecto al módulo visual, encontraron una gran dificultad en detectar la posición de jugadores más alejados
de la cámara, dado que el material con el que trabajaron en general eran cámaras situadas a no más de
18 metros de altura. Esto hacía que la resolución en el lateral opuesto de la cancha sea de 1,5 metros por píxel,
insuficiente para hacer un análisis real de la información obtenida.

Su trabajo utiliza fuertemente la detección de líneas en la cancha, tanto las líneas blancas que demarcan sectores
importantes del campo de juego, como de distintos tonos de verde en franjas que es frecuentemente el caso del césped de
estadios de Europa. Esta característica no se vé en las canchas de fútbol en la mayoría de los países de América Latina.

Para mantener información acerca del movimiento sobre el eje de la cámara (denominado \textit{panning}), se utilizó
un algoritmo de aprendizaje para detectar características en los carteles publicitarios usualmente presentes en los
laterales de la cancha. Esto ayuda a la robustez del algoritmo, pero en ciertos casos no es suficiente, como sucede
cuando el camarógrafo mueve la cámara rápidamente para no perder de vista la pelota en el caso de un pase largo.
El máximo tiempo que reportan para el seguimiento correcto de la orientación y posición de la cámara es de 2,5 minutos.

El análisis del video se compone de las siguientes etapas:

\begin{itemize}
  \item \textbf{Segmentación por color}: Se diferencia el verde de la cancha, los jugadores, la publicidad de fondo,
  y las líneas blancas de la cancha mediante el color de los mismos. Debido a diferencias de
  iluminación, se actualizan los parámetros para la detección de valores que corresponden al pasto verde de acuerdo
  a un algoritmo de aprendizaje que es sensible al ángulo estimado de la cámara y al tiempo.
  \item \textbf{Estimación de la posición de la cámara}: Se tiene un modelo de los bordes rectos que debieran detectarse
  en la cámara, y sus posiciones en tres dimensiones. A partir de esto, se obtienen datos acerca de la perspectiva.
  Para fortalecer la detección, se
  corrigen las posiciones utilizando un algoritmo de aprendizaje que toma como entrada las publicidades que se ven en 
  el extremo opuesto de la cancha.
  \item \textbf{Detección de \textit{blobs}}: Otros objetos que no sean verdes o blancos (pasto o líneas de la cancha)
  son candidatos a ser jugadores o el árbitro. Estos son segmentados y analizados en busca de ciertas características:
  se espera que en general sean más altos que anchos, con segmentos definidos: pelo, camisa, piernas, que son
  aprendidos y actualizados a lo largo del análisis.
\end{itemize}

\section{KILL ME}

En el campo del tracking y la segmentación de objetos en secuencias de imágenes y videos en tiempo real, se pueden diferenciar distintas familias de 
algoritmos que atacan este problema de diversas formas. Una de ellas está conformada por los algoritmos basados en lo que se conoce como \textit{local learning}.
\cite{local-learning}
Estos tipos de algoritmos se caracterizan por definir una función objetivo, y un método de aprendizaje para, a través de un entrenamiento basado en 
muestras, intentar minimizar dicha función. Al este proceso de entrenamiento le sigue el proceso de tracking. Estos algoritmos suelen ser computacionalmente costosos, y 
por lo tanto no les es fácil satisfacer la restricción del tracking en tiempo real.\\

Otra familia de algoritmos se base en lo que se llama \textit{template tracking}. Esta familia también comparte la característica de requerir el aprendizaje o entrenamiento
de ciertos parámetros, por lo que se ubican dentro del conjunto de algoritmos basados en aprendizaje o \textit{learning based}. En esta familia se destacan los algoritmos 
basados en predictores lineales o 
\textit{linear predictors} \cite{alp} \cite{original-linear-predictors}. 
% TODO 
\cite{CITATION NEEDED}. 
Estos algoritmos utilizan templates de tamaño fijo que describir los objetos a trackear. El problema de este tipo de algoritmos radica en que es costoso aprender 
totalmente un template, y que, en principio no resulta sencillo adaptarlos. Es decir, para actualizar un template (por ejemplo cuando el objeto cambia de tamaño, dirección, etc...)
se debe computar o construir un template nuevo desde cero. En \cite{alp}, Holzer, Ilic y Navab, proponen un complejo algoritmo basado en el uso de linear predictors y varias capas
de templates de distintos tamaños, lo que les permiten manejar oclusiones parciales y totales con resultados muy positivos. Además, proponen un atajo computacional para 
modificar un template, calculando eficientemente inversas de matrices. Si bien los resultados obtenidos no son óptimos desde el punto de vista de la restricción del tiempo real, 
se acercan bastante, sin haber realizado mayores optimizaciones, como ser paralelización de ciertas partes del algoritmo, programación GPU, etc...

Por último se encuentran los algoritmos de basados en grafos, o \textit{graph based}. Entre ellos se destaca IFTrace \cite{IFTrace}, el cual se basa en la técnica conocida como 
\textit{Image Foresting Transform} \cite{IFT} y en la técnica de tracking de features, KLT \cite{KLT}. Este algoritmo es muy versátil, ya que las únicas suposiciones que hace son que el objeto trackeado en la imagen consista de un
solo set de pixeles conectados, que puede haber un cambio aguda del color u otras propiedades a lo largo de los bordes del objeto, y que estas propiedades pueden cambiar en el 
tiempo. Este algoritmo se basa en una pequeña segmentación base realizada de forma interactiva por el usuario en el primer frame, pero luego lograr manejar satisfactoriamente
oclusiones parciales y en la mayoría de los casos recuperarse de oclusiones totales. Para modelar la imagen y los objetos se utiliza un grafo, en el cual los pixeles son los nodos, y
estos están conectados mediantes aristas si son adyacentes y tiene un peso o costo. Este costo debe ser una medida de la probabilidad de que los puntos estén separados por el borde del
objeto trackeado. En problemas sencillos puede ser tan simple como el valor absoluto de la diferencia de color entre los pixeles. IFTrace combina el gradiente del color con el 
gradiente de una función de classificación de pixeles difusos, algo así como la similaridad entre el pixel y el set de pixeles del objeto segmentado en el frame anterior. \\

En el marco del tracking aplicado a videos de futbol, hay trabajos
con resultados concretos, como en \cite{paper-suecia-soccer} \cite{papers-tanos}.
Li y Flierl \cite{paper-suecia-soccer} utilizan una conocida técnica para extraer
puntos característicos o \textit{features}, SIFT. SIFT es la sigla para \textit{Scale Invariant Feature Transform}, y como se 
desprende de su nombre, ofrece una transformación para extraer puntos característicos
que son invariantes a cambios de escala y rotaciones. En su trabajo, Li y Flierl utilizan estos 
puntos para obtener una correlación entre vistas y frames. Entonces, utilizan la
información 3D de cada jugador para trackearlos en timepo real. Al compartir esta información 3D con
todas las cámaras y explotando la diversidad de perspectiva del sistema multicámara,
se pueden resolver los problemas causados por oclusiones, de manera muy eficiente.\\

En \cite{papers-tanos}, D'Orazio et al. proponen un sistema de seguimiento de
jugadores y pelota de manera no supervisada que logra detectar posiciones
adelantadas en 35 de 45 casos observados durante un torneo de la liga italiana
de fútbol, obteniendo también dos falsos positivos, en tiempo real. El sistema consiste en seis
cámaras conectadas. El algoritmo ejecutado por cada nodo procesador (uno por
cada cámara) utiliza una técnica de reducción de fondo efectiva para el caso de
un partido de fútbol, aprendizaje no supervizado para la detección de jugadores
y distintos equipos (utilizando el algoritmo BSAS \cite{paper-bsas}), un
sistema de seguimiento basado en trayectoria y \textit{bounding boxes} para el
trackeo de los jugadores y resolución de oclusiones.

\section*{Referencias}
\printbibliography

\end{document}
