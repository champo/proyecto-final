\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[spanish]{babel}
\usepackage[pdftex,usenames,dvipsnames]{color}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage[small,bf]{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{titlesec}
\usepackage{csquotes}
\usepackage[backend=bibtex]{biblatex}
\usepackage{titling}

\DeclareMathOperator*{\argmin}{arg\,min}
\addbibresource{references}
\DeclareFieldFormat[inbook]{citetitle}{#1}

\titleformat{\section}{\small\center\bfseries}{\thesection.}{0.5em}{\normalsize\uppercase}
\titleformat{\subsection}{\small\center\bfseries}{}{0.5em}{\small\uppercase}

\def\customabstract{\vspace{.5em}
    {\small\center{\textbf{RESUMEN}} \\[0.5em] \relax%
    }}
\def\endkeywords{\par}

\def\keywords{\vspace{.5em}
    {\textit{Palabras clave: } 
    }}
\def\endkeywords{\par}

% TITLE Configuration
\setlength{\droptitle}{-30pt}
\pretitle{\begin{center}\Huge\begin{rmfamily}}
\posttitle{\par\end{rmfamily}\end{center}\vskip 0.5em}
\preauthor{\begin{center}
        \large \lineskip 0.5em%
\begin{tabular}[t]{c}}
\postauthor{\end{tabular}\normalsize 
    \\[1em] Estudiantes del Instituto Tecnológico de Buenos Aires
\par\end{center}}
\predate{\begin{center}\small}
\postdate{\par\end{center}}

% Headers
\addtolength{\voffset}{-40pt}
\addtolength{\textheight}{80pt}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\lhead{\small No publicado}
\rhead{\small \thepage}
\cfoot{\small Copyright \copyright 2013 ITBA}

% Metadata
\title{}
\date{20 de Septiembre de 2013}
\author{Civile, Juan Pablo \and Crespo, Álvaro \and Ordano, Esteban }

\begin{document}

\pagestyle{fancy}
\maketitle
\thispagestyle{fancy}

\begin{customabstract}
\textbf{
}
\end{customabstract}

\begin{keywords}
\end{keywords}

\newpage

\part*{Estado del Arte}

% Describir la organizacion de esta seccion

\section{Una camara}

Conocemos 3 familias de algoritmos de tracking en video utilizando una sola camara.
Estas son \textit{Linear Predictors}, \textit{Local learning} y \textit{Graph based}.
Pasamos a describir las tecnicas usadas por estos.

\subsection{Linear predictors}

\textit{Linear Predictor} se refiere a crear una relacion lineal \[ Ax = b \] donde $A$ es un predictor, $x$ un valor medido y $b$ otro segundo valor relacionado a $x$ de alguna manera.
En \cite{alp, original-linear-predictors} los autores utilizan predictores que relacionan muestras tomadas de la imagen con el cambio de posicion del objeto.
Para obtener la relacion $A$ se utiliza un paso inicial de entrenamiento.
Se parte de una posicion conocida y se hacen multiples mutaciones obteniendo $N$ cambios de posiciones $b_i$ y sus correspondientes muestras $x_i$.
Luego se define $X = (x_1, \dots, x_N)$ y $B = (b_1, \dots, b_N)$ y se resuelve $AX = B$.

Una vez calculada $A$, en cada cuadro se toman muestras de la imagen usando la ultima posicion conocida del objeto.
Usando estas muestras se calcula el cambio de posicion del objeto mediante $Ax$.
Para mejorar la efectividad de los algoritmos, se calculan varios predictores y se disponen en capas.
Cada capa se construye para buscar cambios de posicion cada vez mas pequeños.
Es decir, la primer capa busca cambios bruscos y la ultima pequeños cambios.

\citeauthor*{alp} introducen varias tecnicas para hacer mas robusto el algoritmo.
Primero calculan la relacion $A$ de forma tal que puede ser facilmente actualizada para soportar cambios en el objeto.
Esto permite detectar oclusiones parciales y cambiar el predictor para que no busque las partes ocultas del objeto.
Una vez que las partes ocultas del objeto entran en el campo visual de vuelta, se vuelve a agregar las partes del predictor que se quitaron previamente.
Esta tecnica ademas permite reentrenar la relacion $A$ con poco costo computacional.
Luego, para soportar cambios de iluminacion en la imagen siempre ajustan las muestras tomadas a una distribucion normal.

\subsection{Local learning}
% Local learning

El aprendizaje local, o \textit{local learning}, puede resolver razonablemente el problema del seguimiento de objetos en secuencias de imágenes, lo
que ha sido un tema de investigación en el área del aprendizaje automático \cite{local-learning-machine-learnin} y usado principalmente en la clasificación 
de imágenes, recuperación y reconocimiento de objetos. A diferencia del aprendizaje global, \textit{global learning}, que entrena un modelo global basado en 
todos los datos de entrenamiento, local learning considera varios modelos locales, cada uno extraído de solamente un subconjunto de los datos de entrenamiento.
Este tipo de enfoque enfatiza la idea de que un modelo local puede caracterizar mejor las propiedades intrínsecas y discriminativas de su correspondiente 
subconjunto de datos, que un modelo global para el conjunto completo de datos. De esto se desprende que utilizar múltiples modelos locales puede ofrecer 
mejores resultados cuando los datos están distribuidos de manera complicadao o poco clara.\\
Si bien se puede pensar al seguimiento de objetos como una tarea de clasificación binaria 
que apunta a separar el objeto del resto de la imagen o fondo, en realidad, el principal
problema reside en relacionar las apariciones del objeto entre 2 cuadros, \textit{frames},
consecutivos. Es por esto que la métrica de distancia para determinar el grado de 
relación entre los puntos característicos del objeto adquiere muchísima importancia.
Una simple medida de distancia como la distancia Euclideana puede llevar a algoritmos
de tracking inestables a la hora de diferenciar el objeto del fondo de la imagen. Por
lo tano, es necesario diseñar una medida de distancia eficiente y discriminativa. Esta 
es la idea princial que proponen Li y Lu \cite{local-learning}.\\
La función de distancia que usan es una combinación lineal de distancias elementales, 
como se presenta en \cite{malisiewicz-cvpr08}. Definen a la función de distancia de un 
ejemplar (punto característico) $e$, $D_{e}$ como:

\begin{equation}
    \label{eq:distance-exemplar}
    D_{e}(z) = w_{e} \cdot d_{ez}
\end{equation}

donde $w_{e}$ es el vector de pesos de $e$, y $d_{ez}$ es el vector de distancia 
n-dimensional entre $e$ y $z$, cuya n-ésima componente es la distancia $L_{2}$ 
entre la característica n-ésima de $e$ y $z$.\\
Cada ejemplar está también asociado con un vector binario $B_{e}$, cuyos elementos 
no nulos implican que los ejemplares correspondientes son similares a $e$. La 
longitud de $B_{e}$ es igual al número de ejemplares con el mismo rótulo de $e$.
Asumiendo que el aprendizaje de cada una de las funciones de distancia es 
independiente del resto, se puede aprender $w_{e}$ y $B_{e}$, en un problema 
de aprendizaje formulado de la siguiente manera:

\begin{equation}
    \label{eq:learning-problem}
    f_{1}(w,B) = \sum_{i \in C} B_{i}L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}
\begin{equation}
    {w^{*}, B^{*} = \argmin_{w,b} f_{1} (w,b) }
\end{equation}
\begin{equation}
   w \geq 0, B_{i} \in {0,1}, \sum_{i} B_{i} = M
\end{equation}

El conjunto $C$ es el conjunto de todos los ejemplares con el mismo rótulo que $e$ y $M$ 
es el mínimo número de ejemplares similares a $e$ (predefinido). La función $L$ puede ser
cualquier función de costo o pérdida, \textit{loss function}, positiva.
El vector de pesos $w$
se requiere que sea positivo para asegurar que una mayor distancia elemental (entre 
alguna de las características) no pueda nunca llevar a una menor distancia total, 
lo que implicaría una mayor similaridad.\\

Previo al seguimiento se deben especificar manualmente algunos parámetros iniciales, 
como ser: punto central, ancho, altura y rotación del objeto. En el proceso de 
entrenamiento, se aplica un Análisis de la Componente Principal (PCA, 
\textit{Principal Component Analysis}) de forma incremental en los primeros $F$ cuadros.
Los resultados se seleccionan como muestras de entrenamiento positivas, mientrás que
los peores resultados, se toman como muestras negativas. Se obtienen las características 
RGB y LBP, como se presentan en \cite{tracking-bag-of-features}, de todas las muestras, 
tanto positivas como negativas. Para cada muestra de entrenamiento, se calculan las 
distancias elementales RGB y LBP con respecto a todas las restantes muestras.
Para obtener el vector de pesos óptimo, $w^{*}$, se estimar iterativamente $B$, 
en función de $w$, y $w$ en función de $B$, asegurando que el valor de $f_{1}$ nunca 
crezca, para encontrar un mínimo local. Este proceso iterativo se modelar de la 
siguiente forma:

\begin{equation}
   \label{eq:local-learning-B-k}
   B^{k} = \argmin_{B} \sum_{i \in C} B_{i}L(-w^{k} \cdot d_{i})
\end{equation}
\begin{equation}
    \label{eq:local-learning-w-k}
    w^{k+1} = \argmin_{w} \sum_{i:B_{i}^{k}=1} L(-w \cdot d_{i}) + \sum_{i\notin C}L(w \cdot d_{i})
\end{equation}

Dado un $w^{k}$, que inicialmente podría ser aleatorio, se minimiza la ecuación 
\ref{eq:local-learning-B-k} fijando $B_{i} = 1$ para los $M$ valores más
pequeños de $L(-w \cdot d_{i})$ y $0$ para el resto. Dado $B^{k}$, se puede
obtener fácilmente $w^{k}$, resolviendo la ecuación \ref{eq:local-learning-w-k}. 
El aprendizaje termina cuando $B^{k+1}=B^{k}$.\\

En el proceso de seguimiento, para cada cuadro nuevo, se generan los
candidatos de manera aleatoria, utilizando un filtro de partículas,
\textit{particle filter}, alrededor del resultado del 
seguimiento en el cuadro anterior. Luego, se extraen las características
RGB Y LBP como muestras de testeo. Después de calcular las distancias
elementales entre las muestras de testeo y de entrenamiento, se 
forma una matriz de distancia, $DM: N_{test} \times N_{train}$ a través
de las funciones de distancia entrenadas. Finalmente, se utiliza la 
matriz $DM$ para localizar al objeto como sigue:

\begin{equation}
    T = \argmin_{t} c \sum_{i} D_{i}(t) + (1 - c) \sum_{j} D_{j}(t)
\end{equation}

\begin{equation}
    \forall i \in \{i : i \in S^{+}, D_{i}(t) \leq Thr_{D} \}
\end{equation}
\begin{equation}
    \forall j \in \{j : j \in S^{+}, D_{j}(t) > Thr_{D} \}
\end{equation}

Donde $t$ es un posible candidato y $T$ es el objeto. $S^{+}$ es el 
conjunto de muestras de entrenamiento positivas. La idea consiste en 
que las muestras cuyas distancias sean menor que el umbral $Thr_{D}$
contribuyan más a localizar el objeto, entonces la constante $c$ 
debería tener un valor acorde, $c > 0.5$ (0.7).\\

El algoritmo de seguimiento se complementa con una adición más, que 
intenta atacar el problema de los cambios de poses y las oclusiones.
Para esto es necesario actualizar el modelo que se tiene para 
que efectivamente pueda manejar estas dificultades. 
Haciendo uso del umbral de distancia $Thr_{D}$ para prevenir
malas actualizaciones, se intenta realizar correciones al modelo,
en este caso, las funciones de distancia. Esto es, una distancia
menor a $Thr_{D}$ indica se el candidato pertence a la misma clase,
mientras que una distancia mayor indica lo contrario. Utilizando 
la ecuación \ref{eq:learning-model-update}, se agregan candidatos,
como muestras positivas de entrenamiento y, cada 5 cuadros, 
se utiliza el conjunto actualizado de entrenamiento para 
reentrenar todas las funciones de distancia.

\begin{equation}
    \label{eq:learning-model-update}
    t_{label} = \left\{ 
                \begin{array}{l l}
                    1, & D_{S^{+}}}(t) \leq Tht_{D}\\
                    0, & D_{S^{+}}}(t) >  Tht_{D}
                \end{array} \right.
\end{equation}

\begin{equation}
    D_{S^{+}}}(t) = \dfrac{1}{N_{S^{+}}} \sum_{i \in S^{+}} D_{i}(t)
\end{equation}

En la ecuación \ref{eq:learning-model-update}, $N_{S^{+}}$ es el 
número de muestras positivas de entrenamiento y $D_{S^{+}}}(t)$
es el promedio de distancia del candidato $t$ a las muestras
de entrenamiento positivas.

\subsection{Graph based}
% IFTrace

\section{6 camaras}

% Tanos

\section{8 camaras}

\section{Multiples camaras}

% SIFT Base blablablabla
\subsection{Camera-based Observation of Football Games for Analyzing Multi-agent Activities}

\citeauthor*{beetz-05, beetz-06} analizaron, desde el punto de vista de la inteligencia artificial,
el problema de detectar el comportamiento de los jugadores dentro de la cancha. Para eso, propusieron
un sistema con dos módulos, uno que extrae características e información de videos provenientes de
un numero indeterminado de cámaras, y un módulo de análisis y seguimiento del comportamiento de cada
objeto (un sector de la imágen candidato a ser la pelota o una persona en el campo de juego, 
llamado \textit{blob} por los autores).

Respecto al módulo visual, encontraron una gran dificultad en detectar la posición de jugadores más alejados
de la cámara, dado que el material con el que trabajaron en general eran cámaras situadas a no más de
18 metros de altura. Esto hacía que la resolución en el lateral opuesto de la cancha sea de 1,5 metros por píxel,
insuficiente para hacer un análisis real de la información obtenida.

Su trabajo utiliza fuertemente la detección de líneas en la cancha, tanto las líneas blancas que demarcan sectores
importantes del campo de juego, como de distintos tonos de verde en franjas que es frecuentemente el caso del césped de
estadios de Europa. Esta característica no se vé en las canchas de fútbol en la mayoría de los países de América Latina.

Para mantener información acerca del movimiento sobre el eje de la cámara (denominado \textit{panning}), se utilizó
un algoritmo de aprendizaje para detectar características en los carteles publicitarios usualmente presentes en los
laterales de la cancha. Esto ayuda a la robustez del algoritmo, pero en ciertos casos no es suficiente, como sucede
cuando el camarógrafo mueve la cámara rápidamente para no perder de vista la pelota en el caso de un pase largo.
El máximo tiempo que reportan para el seguimiento correcto de la orientación y posición de la cámara es de 2,5 minutos.

El análisis del video se compone de las siguientes etapas:

\begin{itemize}
  \item \textbf{Segmentación por color}: Se diferencia el verde de la cancha, los jugadores, la publicidad de fondo,
  y las líneas blancas de la cancha mediante el color de los mismos. Debido a diferencias de
  iluminación, se actualizan los parámetros para la detección de valores que corresponden al pasto verde de acuerdo
  a un algoritmo de aprendizaje que es sensible al ángulo estimado de la cámara y al tiempo.
  \item \textbf{Estimación de la posición de la cámara}: Se tiene un modelo de los bordes rectos que debieran detectarse
  en la cámara, y sus posiciones en tres dimensiones. A partir de esto, se obtienen datos acerca de la perspectiva.
  Para fortalecer la detección, se
  corrigen las posiciones utilizando un algoritmo de aprendizaje que toma como entrada las publicidades que se ven en 
  el extremo opuesto de la cancha.
  \item \textbf{Detección de \textit{blobs}}: Otros objetos que no sean verdes o blancos (pasto o líneas de la cancha)
  son candidatos a ser jugadores o el árbitro. Estos son segmentados y analizados en busca de ciertas características:
  se espera que en general sean más altos que anchos, con segmentos definidos: pelo, camisa, piernas, que son
  aprendidos y actualizados a lo largo del análisis.
\end{itemize}

Luego del análisis de características del video, el procesamiento y seguimiento de los jugadores es realizado utilizando
una extensión del algoritmo \textbf{Multiple Hypothesis Tracking(MHT)} \cite{MHT-1, MHT-2} mejorado por \citeauthor*{Schmitt-1, Schmitt-2}
Este algoritmo utiliza un modelo de cámara y movimiento probabilístico para estimar la posición de los jugadores
y actualizarlas en cada observación. Se utilizan muchas hipótesis propias de las características de un partido
de fútbol para mejorar esta estimación: 
\begin{itemize}
  \item \textbf{Trackeo de personas}: No se dá el caso de que un jugador desaparezca de la cancha de un \textit{frame}
  a otro. Aparecen gradualmente desde el borde del campo de visión.
  \item \textbf{Oclusiones entre jugadores}: No se descarta la información sobre la estimación de un jugador cuando 
  éste pasa a estar ocluído por otro jugador.
  \item \textbf{Jugadores sobre un plano}: Se asume que la cancha es un plano tridimencional y que los jugadores
  están posicionados sobre este plano. Esto además permite relacionar el tamaño de los \textit{blobs} con la cercanía
  del jugador a la cámara.
\end{itemize}

Por último, este análisis genera información de alto nivel semántico en forma de \textit{movimientos}
y \textit{episodios}. Para modelar los movimientos de la pelota, se asumió que la pelota se mueve linealmente por partes.
Un episodio es definido como la secuencia de \textit{movimientos} de la pelota desde que un jugador toma control
de ella hasta que lo pierde. Los movimientos exitosos que un jugador ejecuta en este modelo son pases, tiros al arco,
o cambios bruscos de dirección (llamado \textit{dribbling} por los autores).

\section{Video televizado}

\subsection{\citetitle{Liu20061146}}

En \cite{Liu20061146} se plantea una tecnica para obtener las posiciones de los jugadores y la pelota utilizando la transmision televizada de un partido de futbol.
El algoritmo se puede dividir en los siguientes grandes rasgos:
\begin{itemize}
\item Estimacion de la relacion entre puntos en la imagen y coordenadas en la cancha
\item Estimacion de la posicion de la camara en las coordenadas del mundo
\item Deteccion y tracking de la pelota
\item Deteccion de la cancha
\item Deteccion de los jugadores
\end{itemize}

Para estimar la relacion entre los puntos en la imagen y las coordenadas en la cancha se calcula una homografia.
Siendo $M = (x, y, 1)$ un punto en el plano de la cancha en coordenadas homogeneas y $m = (u, v, 1)$ la posicion del punto en la imagen, se puede convertir $ m = H M $.

Como la perspectiva de la camara cambia cuadro a cuadro, esta debe ser calculada en cada cuadro nuevamente.
Si en la imagen actual se encuentran 4 puntos conocidos (Esquinas de la cancha o de las areas), la homografia puede ser calculada directamente.
De no ser asi, se estima considerando que la homografia del cuadro actual $H_t$ se puede relacionar con $H_{t-1}$ mediante un \textit{Global Motion Parameter} $P$.
Este parametro $P_{t-1,t}$ se calcula tomando una serie de puntos en la imagen y relacionando su posicion entre el cuadro $t-1$ y $t$.
Luego $ H_t = H_{t-1} P_{t-1,t}$.

Para obtener la posicion de la camara se descompone la homografia en 2 matrices:
\begin{equation}
H = K \begin{bmatrix} r_1 & r_2 & t \end{bmatrix}
K = \begin{pmatrix} 
    \alpha & \gamma & u_0 \\
    0 & \beta & v_0 \\
    0 & 0 & 1
    \end{pmatrix}
\end{equation}

Donde $\alpha$, $\beta$ representan la amplitud focal de la camara, $\gamma$ representa el \textit{skew} y $(u_0, v_0)$ es la coordenada del punto principal.
Se asume que la amplitud focal se mantiene constante, $\gamma = 0$ y el punto principal es el centro de la imagen.
$r_1$, $r_2$ son parte de una rotacion $R = (r_1, r_2, r_1 \times r_2)$, y $t$ son las coordenadas del origen de la cancha en coordenadas de la imagen.
Conocidas $H$ y $K$ se puede calcular la posicion de la camara como $R^{-1} t$.
Para el calculo de $K$ se necesita $\alpha$ y $\beta$ que se calcula usando $P$ de la siguiente manera:

\begin{equation}
\begin{bmatrix}
    p_{1 1} p_{2 1} & p_{1 2} p_{2 2} \\
    p_{1 1} p_{3 1} & p_{1 2} p_{3 2} \\
    p_{1 1} p_{3 1} & p_{2 2} p_{3 2} 
\end{bmatrix} 
\begin{bmatrix}
    \alpha^2 \\
    \beta^2
\end{bmatrix}
 =
\begin{bmatrix}
    - p_{1 3} p_{2 3} \\
    - p_{1 3} p_{3 3} \\
    - p_{2 3} p_{3 3} \\
\end{bmatrix}
\end{equation}

\subsubsection*{Seguimiento de la pelota}

El algoritmo planteado para seguimiento de la pelota tiene 2 etapas.
La primer etapa es de deteccion utilizando un algoritmo basado en \textit{Viterbi}.
La segunda etapa es de seguimiento utilizando un \textit{Kalman Filter}.

Para deteccion se crea una imagen binaria, segmentando segun la caracteristica blanca de la pelota.
Una vez segmentada, se eliminan los candidatos teniendo en cuenta las distintas caracteristicas morfologicas de la pelota. 
Esta operacion se realiza en $T$ cuadros distintos, a partir de esto se construye un grafo pesado.
Los nodos de este grafo representan candidatos, con un peso segun que tan parecidos son a una pelota ideal.
Y los vertices se colocan si estan a una cierta proximidad y pesados segun que tan cerca y parecidos sean los nodos.
Sobre este grafo se hace una busqueda de camino optimo, y de este la posicion de la pelota en el ultimo cuadro.

Una vez detectada la pelota, se utiliza tracking hasta que no se confia en el resultado del algoritmo de tracking.
En esa instancia se vuelve a detectar la pelota con el algoritmo dicho anteriormente.

\subsubsection*{Deteccion de la cancha}

\subsubsection*{Deteccion de jugadores}


\section{KILL ME}

En el campo del tracking y la segmentación de objetos en secuencias de imágenes y videos en tiempo real, se pueden diferenciar distintas familias de 
algoritmos que atacan este problema de diversas formas. Una de ellas está conformada por los algoritmos basados en lo que se conoce como \textit{local learning}.
\cite{local-learning}
Estos tipos de algoritmos se caracterizan por definir una función objetivo, y un método de aprendizaje para, a través de un entrenamiento basado en 
muestras, intentar minimizar dicha función. Al este proceso de entrenamiento le sigue el proceso de tracking. Estos algoritmos suelen ser computacionalmente costosos, y 
por lo tanto no les es fácil satisfacer la restricción del tracking en tiempo real.\\

Otra familia de algoritmos se base en lo que se llama \textit{template tracking}. Esta familia también comparte la característica de requerir el aprendizaje o entrenamiento
de ciertos parámetros, por lo que se ubican dentro del conjunto de algoritmos basados en aprendizaje o \textit{learning based}. En esta familia se destacan los algoritmos 
basados en predictores lineales o 
\textit{linear predictors} \cite{alp} \cite{original-linear-predictors}. 
% TODO 
\cite{CITATION NEEDED}. 
Estos algoritmos utilizan templates de tamaño fijo que describir los objetos a trackear. El problema de este tipo de algoritmos radica en que es costoso aprender 
totalmente un template, y que, en principio no resulta sencillo adaptarlos. Es decir, para actualizar un template (por ejemplo cuando el objeto cambia de tamaño, dirección, etc...)
se debe computar o construir un template nuevo desde cero. En \cite{alp}, Holzer, Ilic y Navab, proponen un complejo algoritmo basado en el uso de linear predictors y varias capas
de templates de distintos tamaños, lo que les permiten manejar oclusiones parciales y totales con resultados muy positivos. Además, proponen un atajo computacional para 
modificar un template, calculando eficientemente inversas de matrices. Si bien los resultados obtenidos no son óptimos desde el punto de vista de la restricción del tiempo real, 
se acercan bastante, sin haber realizado mayores optimizaciones, como ser paralelización de ciertas partes del algoritmo, programación GPU, etc...

Por último se encuentran los algoritmos de basados en grafos, o \textit{graph based}. Entre ellos se destaca IFTrace \cite{IFTrace}, el cual se basa en la técnica conocida como 
\textit{Image Foresting Transform} \cite{IFT} y en la técnica de tracking de features, KLT \cite{KLT}. Este algoritmo es muy versátil, ya que las únicas suposiciones que hace son que el objeto trackeado en la imagen consista de un
solo set de pixeles conectados, que puede haber un cambio aguda del color u otras propiedades a lo largo de los bordes del objeto, y que estas propiedades pueden cambiar en el 
tiempo. Este algoritmo se basa en una pequeña segmentación base realizada de forma interactiva por el usuario en el primer frame, pero luego lograr manejar satisfactoriamente
oclusiones parciales y en la mayoría de los casos recuperarse de oclusiones totales. Para modelar la imagen y los objetos se utiliza un grafo, en el cual los pixeles son los nodos, y
estos están conectados mediantes aristas si son adyacentes y tiene un peso o costo. Este costo debe ser una medida de la probabilidad de que los puntos estén separados por el borde del
objeto trackeado. En problemas sencillos puede ser tan simple como el valor absoluto de la diferencia de color entre los pixeles. IFTrace combina el gradiente del color con el 
gradiente de una función de classificación de pixeles difusos, algo así como la similaridad entre el pixel y el set de pixeles del objeto segmentado en el frame anterior. \\

En el marco del tracking aplicado a videos de futbol, hay trabajos
con resultados concretos, como en \cite{paper-suecia-soccer} \cite{papers-tanos}.
Li y Flierl \cite{paper-suecia-soccer} utilizan una conocida técnica para extraer
puntos característicos o \textit{features}, SIFT. SIFT es la sigla para \textit{Scale Invariant Feature Transform}, y como se 
desprende de su nombre, ofrece una transformación para extraer puntos característicos
que son invariantes a cambios de escala y rotaciones. En su trabajo, Li y Flierl utilizan estos 
puntos para obtener una correlación entre vistas y frames. Entonces, utilizan la
información 3D de cada jugador para trackearlos en timepo real. Al compartir esta información 3D con
todas las cámaras y explotando la diversidad de perspectiva del sistema multicámara,
se pueden resolver los problemas causados por oclusiones, de manera muy eficiente.\\

En \cite{papers-tanos}, D'Orazio et al. proponen un sistema de seguimiento de
jugadores y pelota de manera no supervisada que logra detectar posiciones
adelantadas en 35 de 45 casos observados durante un torneo de la liga italiana
de fútbol, obteniendo también dos falsos positivos, en tiempo real. El sistema consiste en seis
cámaras conectadas. El algoritmo ejecutado por cada nodo procesador (uno por
cada cámara) utiliza una técnica de reducción de fondo efectiva para el caso de
un partido de fútbol, aprendizaje no supervizado para la detección de jugadores
y distintos equipos (utilizando el algoritmo BSAS \cite{paper-bsas}), un
sistema de seguimiento basado en trayectoria y \textit{bounding boxes} para el
trackeo de los jugadores y resolución de oclusiones.

\section*{Referencias}
\printbibliography

\end{document}
